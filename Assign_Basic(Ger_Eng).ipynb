{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assign_Basic(Ger_Eng).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJxJLfT6m4zo",
        "colab_type": "text"
      },
      "source": [
        "# Machine Translation\n",
        "\n",
        "German-English"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvFSu3KOnCQI",
        "colab_type": "text"
      },
      "source": [
        "# 1)- Importing key modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydSdCo4JzRta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#support both Python 2 and Python 3 with minimal overhead.\n",
        "from __future__ import absolute_import, division, print_function\n",
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXdjBXc-zNXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string \n",
        "import re \n",
        "from numpy import array, argmax, random, take \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "% matplotlib inline \n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElRcz5K3hJrC",
        "colab_type": "code",
        "outputId": "c3b5a551-76f1-4796-d1ac-a5670b0b3d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model \n",
        "from keras import optimizers \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN_b91atnHye",
        "colab_type": "text"
      },
      "source": [
        "# 2)- Reading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM1ZO53WhL_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to read raw text file\n",
        "def read_text(filename): \n",
        "        # open the file \n",
        "        file = open(filename, mode='rt', encoding='utf-8') \n",
        "        \n",
        "        # read all text \n",
        "        text = file.read() \n",
        "        file.close() \n",
        "        return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nJ3NaVchcWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split text into sentences \n",
        "def to_lines(text): \n",
        "      sents = text.strip().split('\\n') \n",
        "      sents = [i.split('\\t') for i in sents] \n",
        "      return sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liHFTvu6hffX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = read_text(\"merged2015.txt\") \n",
        "deu_eng = to_lines(data) \n",
        "deu_eng = array(deu_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LoUaSevh0Z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#deu_eng = deu_eng[:50000,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX6QuO7xh6RK",
        "colab_type": "text"
      },
      "source": [
        "# 3)-Text Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ewE-nHLh3ph",
        "colab_type": "code",
        "outputId": "bba935b3-57a6-401d-b668-3d4a17ac126d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "deu_eng"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['india and japan prime ministers meet in tokyo',\n",
              "        'die premierminister indiens und japans trafen sich in tokio'],\n",
              "       ['indias new prime minister narendra modi is meeting his japanese counterpart shinzo abe in tokyo to discuss economic and security ties on his first major foreign visit since winning mays election',\n",
              "        'indiens neuer premierminister narendra modi trifft bei seinem ersten wichtigen auslandsbesuch seit seinem wahlsieg im mai seinen japanischen amtskollegen shinzo abe in toko um wirtschaftliche und sicherheitspolitische beziehungen zu besprechen'],\n",
              "       ['mr modi is on a fiveday trip to japan to strengthen economic ties with the third largest economy in the world',\n",
              "        'herr modi befindet sich auf einer funftagigen reise nach japan um die wirtschaftlichen beziehungen mit der drittgroten wirtschaftsnation der welt zu festigen'],\n",
              "       ...,\n",
              "       ['five minutes later the first mountainbikers set off',\n",
              "        'funf minuten spater legten die ersten mountainbiker los'],\n",
              "       ['bent hansen chairman of the association cycling on the grosser feldberg gave the starting orders and wished those taking part an enjoyable trip',\n",
              "        'bent hansen vorsitzender des vereins radeln auf den groen feldberg gab die startkommandos und wunschte den teilnehmern einen schonen ausflug'],\n",
              "       ['next year he hopes to have safety barriers on the course for the benefit of those taking part on the feldberg',\n",
              "        'fur nachstes jahr hoffe er dass es gelingt die strecke zum feldberg hinauf zur sicherheit der teilnehmer zu sperren']],\n",
              "      dtype='<U511')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wStmPrUddr9E",
        "colab_type": "code",
        "outputId": "35a66737-2713-454a-afa8-5b3caf920963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(deu_eng)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxFu03nLeK4T",
        "colab_type": "code",
        "outputId": "4aee31f2-4b62-42cd-cc6d-a447382dbe0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "deu_eng[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['india and japan prime ministers meet in tokyo',\n",
              "       'die premierminister indiens und japans trafen sich in tokio'],\n",
              "      dtype='<U511')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_6AWqwveSe7",
        "colab_type": "code",
        "outputId": "fdccc0b8-c520-451f-bdb2-6f6b204d5599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "deu_eng[:5]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['india and japan prime ministers meet in tokyo',\n",
              "        'die premierminister indiens und japans trafen sich in tokio'],\n",
              "       ['indias new prime minister narendra modi is meeting his japanese counterpart shinzo abe in tokyo to discuss economic and security ties on his first major foreign visit since winning mays election',\n",
              "        'indiens neuer premierminister narendra modi trifft bei seinem ersten wichtigen auslandsbesuch seit seinem wahlsieg im mai seinen japanischen amtskollegen shinzo abe in toko um wirtschaftliche und sicherheitspolitische beziehungen zu besprechen'],\n",
              "       ['mr modi is on a fiveday trip to japan to strengthen economic ties with the third largest economy in the world',\n",
              "        'herr modi befindet sich auf einer funftagigen reise nach japan um die wirtschaftlichen beziehungen mit der drittgroten wirtschaftsnation der welt zu festigen'],\n",
              "       ['high on the agenda are plans for greater nuclear cooperation',\n",
              "        'plane fur eine starkere kerntechnische zusammenarbeit stehen ganz oben auf der tagesordnung'],\n",
              "       ['india is also reportedly hoping for a deal on defence collaboration between the two nations',\n",
              "        'berichten zufolge hofft indien daruber hinaus auf einen vertrag zur verteidigungszusammenarbeit zwischen den beiden nationen']],\n",
              "      dtype='<U511')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1FK1T2Kicbi",
        "colab_type": "code",
        "outputId": "bb901b1f-aa45-4266-913b-48d7579d2732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "# for english part \n",
        "deu_eng[:,0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['india and japan prime ministers meet in tokyo',\n",
              "       'indias new prime minister narendra modi is meeting his japanese counterpart shinzo abe in tokyo to discuss economic and security ties on his first major foreign visit since winning mays election',\n",
              "       'mr modi is on a fiveday trip to japan to strengthen economic ties with the third largest economy in the world',\n",
              "       ..., 'five minutes later the first mountainbikers set off',\n",
              "       'bent hansen chairman of the association cycling on the grosser feldberg gave the starting orders and wished those taking part an enjoyable trip',\n",
              "       'next year he hopes to have safety barriers on the course for the benefit of those taking part on the feldberg'],\n",
              "      dtype='<U511')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keSiAeBoeXxT",
        "colab_type": "text"
      },
      "source": [
        "**This shows all the dataset. I expect to show english version only.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2CAJPD_ifVc",
        "colab_type": "code",
        "outputId": "7bf3143b-8bff-4d2a-ce84-d8548861c8e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "# for german part of lang.\n",
        "deu_eng[:,1]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['die premierminister indiens und japans trafen sich in tokio',\n",
              "       'indiens neuer premierminister narendra modi trifft bei seinem ersten wichtigen auslandsbesuch seit seinem wahlsieg im mai seinen japanischen amtskollegen shinzo abe in toko um wirtschaftliche und sicherheitspolitische beziehungen zu besprechen',\n",
              "       'herr modi befindet sich auf einer funftagigen reise nach japan um die wirtschaftlichen beziehungen mit der drittgroten wirtschaftsnation der welt zu festigen',\n",
              "       ..., 'funf minuten spater legten die ersten mountainbiker los',\n",
              "       'bent hansen vorsitzender des vereins radeln auf den groen feldberg gab die startkommandos und wunschte den teilnehmern einen schonen ausflug',\n",
              "       'fur nachstes jahr hoffe er dass es gelingt die strecke zum feldberg hinauf zur sicherheit der teilnehmer zu sperren'],\n",
              "      dtype='<U511')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RauipdAfdl7H",
        "colab_type": "text"
      },
      "source": [
        "**I want to apply slice method as in array. Then I have one array with english version and other array in german. This not happening.\n",
        "So when I will try to apply text cleaning or any other modeling technique, my data does not act as expected.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEia-m7ViPLD",
        "colab_type": "text"
      },
      "source": [
        "### 3.1)-Text cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmC81k-wh8ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove punctuation \n",
        "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]] \n",
        "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]] \n",
        "\n",
        "# convert text to lowercase \n",
        "for i in range(len(deu_eng)): \n",
        "    deu_eng[i,0] = deu_eng[i,0].lower() \n",
        "    deu_eng[i,1] = deu_eng[i,1].lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FdyDdXwiS9i",
        "colab_type": "text"
      },
      "source": [
        "### 3.2)-Text to Sequence Conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pxu1-xNh8cA",
        "colab_type": "code",
        "outputId": "63546fb0-056a-4343-ea68-75cbf2aa535f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# empty lists \n",
        "eng_l = [] \n",
        "deu_l = [] \n",
        "\n",
        "# populate the lists with sentence lengths \n",
        "for i in deu_eng[:,0]: \n",
        "      eng_l.append(len(i.split())) \n",
        "\n",
        "for i in deu_eng[:,1]: \n",
        "      deu_l.append(len(i.split())) \n",
        "\n",
        "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
        "length_df.hist(bins = 30) \n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2De4ZERJzX_4",
        "colab_type": "text"
      },
      "source": [
        "the maximum length of the German sentences is 8 and that of the English phrases is 6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpt6tCjfkGKu",
        "colab_type": "text"
      },
      "source": [
        "### 3.3)-vectorize our text data \n",
        "\n",
        "by using Kerasâ€™s Tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j_y_uZ7h8e6",
        "colab_type": "code",
        "outputId": "8aa1ed4c-081f-4dc0-ffa4-c18c47990d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# function to build a tokenizer \n",
        "def tokenization(lines): \n",
        "      tokenizer = Tokenizer() \n",
        "      tokenizer.fit_on_texts(lines) \n",
        "      return tokenizer\n",
        "\n",
        "# prepare english tokenizer \n",
        "eng_tokenizer = tokenization(deu_eng[:, 0]) \n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1 \n",
        "eng_length = 8 \n",
        "\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 7231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ha_ZNySh8hh",
        "colab_type": "code",
        "outputId": "6b557cb3-22d9-492d-afe2-db3ad8a9b048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# prepare Deutch tokenizer \n",
        "deu_tokenizer = tokenization(deu_eng[:, 1]) \n",
        "deu_vocab_size = len(deu_tokenizer.word_index) + 1 \n",
        "deu_length = 8 \n",
        "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deutch Vocabulary Size: 9284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvmowmplzfdT",
        "colab_type": "text"
      },
      "source": [
        "There is difference in amount of words in two languages.We need to encode sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUY-Py6WzhtB",
        "colab_type": "text"
      },
      "source": [
        "### 3.4)-encode and pad sequences "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QElAizsykOtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_sequences(tokenizer, length, lines):          \n",
        "         # integer encode sequences          \n",
        "         seq = tokenizer.texts_to_sequences(lines)          \n",
        "         # pad sequences with 0 values          \n",
        "         seq = pad_sequences(seq, maxlen=length, padding='post')           \n",
        "         return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "408A3w7Ukb4r",
        "colab_type": "text"
      },
      "source": [
        "# 4)-Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJF5iWUOnUgC",
        "colab_type": "text"
      },
      "source": [
        "### 4.1)- Train-test Split\n",
        "\n",
        "80%-20%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzxozTM0kZk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# split data into train and test set \n",
        "train,test= train_test_split(deu_eng,test_size=0.2,random_state= 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvyO7SdQkr88",
        "colab_type": "text"
      },
      "source": [
        "### 4.2)- Defining input and target\n",
        "We will encode German sentences as the input sequences and English sentences as the target sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJvJMU9Vzr-7",
        "colab_type": "code",
        "outputId": "ff65c2f5-b573-4ae6-83ff-396948cd5b25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# english version\n",
        "train[:, 0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['its not my responsibility',\n",
              "       'meanwhile in our homes items as innocuous as floor tiles or shed roofs have routinely contained asbestos',\n",
              "       'she said i keep thinking this world did not get better within these years',\n",
              "       ...,\n",
              "       'crops are rotting in the fields mines have been deserted and the markets have been abandoned the virus has cost the region dearly',\n",
              "       'the preparations for the party are well underway in tannenwald gun club which will celebrate years since being established on to september',\n",
              "       'it also means higher taxes'], dtype='<U511')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcMT6wFoztLT",
        "colab_type": "code",
        "outputId": "a0350a52-10b3-42aa-ae48-d1c7c88984e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# english version\n",
        "train[:, 1]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ich bin nicht dafur verantwortlich',\n",
              "       'und derweil haben so unschuldige gegenstande in unseren hausern wie fubodenplatten oder schuppendacher standardmaig asbest enthalten',\n",
              "       'sie sagte ich denke immer dass diese welt in diesen jahren nicht besser geworden ist',\n",
              "       ...,\n",
              "       'die ernte verrottet auf den feldern die minen sind verlassen und die markte verwaist das virus hat der region schwer zugesetzt',\n",
              "       'auf hochtouren laufen beim schutzenverein tannenwald die vorbereitungen fur das grundungsfest von bis september',\n",
              "       'sie bedeutet auch hohere steuern'], dtype='<U511')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6ZhWiJdkkb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare training data \n",
        "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1]) \n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0]) \n",
        "\n",
        "# prepare validation data \n",
        "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1]) \n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2LKJrFfz0GI",
        "colab_type": "code",
        "outputId": "c908f8ef-5b53-4461-b1fe-6f0f56f129b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "print(trainX[:5])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  15  184   18  272 1521    0    0    0]\n",
            " [1071   30 2751   59 6215 6216   85 1223]\n",
            " [ 197    4  261  100   18  323  708   16]\n",
            " [6478   55 1233  208 6479 6480  956 1466]\n",
            " [ 264    5  550    6    4  592    6  180]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L81CkA-Rz0Jh",
        "colab_type": "code",
        "outputId": "6cfd728e-d74f-4143-dc32-ca41d733bc5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "print(trainY[:5])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  48   23   51 4075    0    0    0    0]\n",
            " [2904   64 2016 5284   17 5285 2943   65]\n",
            " [ 141   97   23   98  179  362  193   58]\n",
            " [  69  610  427   23 1523 1892 2202 5445]\n",
            " [1329    3  113   76    1  204 3174    4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plUoF_-gz0Mh",
        "colab_type": "code",
        "outputId": "c021afb1-ad50-4340-a725-f430f72270d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "print(testX.shape)\n",
        "print(testY.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5205, 8)\n",
            "(5205, 8)\n",
            "(1302, 8)\n",
            "(1302, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ubte9AUngfx",
        "colab_type": "text"
      },
      "source": [
        "### 4.3)- build NMT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yORpCfMCkkjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def build_model(in_vocab,out_vocab, in_timesteps,out_timesteps,n):   \n",
        "      model = Sequential() \n",
        "      model.add(Embedding(in_vocab, n, input_length=in_timesteps,   \n",
        "      mask_zero=True)) \n",
        "      model.add(LSTM(n)) \n",
        "      model.add(RepeatVector(out_timesteps)) \n",
        "      model.add(LSTM(n, return_sequences=True))  \n",
        "      model.add(Dense(out_vocab, activation='softmax')) \n",
        "      return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_0LMdC6lgnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model compilation (with 512 hidden units)\n",
        "model = build_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)\n",
        "\n",
        "rms = optimizers.RMSprop(lr=0.001) \n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA8KW2_80Hs3",
        "colab_type": "code",
        "outputId": "ea1ce522-4cef-4c62-b53a-4f7660adfb88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 8, 512)            4753408   \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 512)               2099200   \n",
            "_________________________________________________________________\n",
            "repeat_vector_3 (RepeatVecto (None, 8, 512)            0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 8, 512)            2099200   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8, 7231)           3709503   \n",
            "=================================================================\n",
            "Total params: 12,661,311\n",
            "Trainable params: 12,661,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M1ukVFAlkFz",
        "colab_type": "code",
        "outputId": "4868f981-d2ed-41a9-f969-03a9309f6089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "filename = 'model_translate.h1' \n",
        "\n",
        "# set checkpoint\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss',  \n",
        "                             verbose=1, save_best_only=True, \n",
        "                             mode='min') \n",
        "\n",
        "\n",
        "# train model \n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
        "                    epochs=30, batch_size=512, validation_split = 0.2, \n",
        "                    callbacks=[checkpoint], verbose=1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Train on 4164 samples, validate on 1041 samples\n",
            "Epoch 1/30\n",
            "4164/4164 [==============================] - 9s 2ms/step - loss: 7.8991 - acc: 0.0526 - val_loss: 6.9161 - val_acc: 0.0946\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 6.91614, saving model to model_translate.h1\n",
            "Epoch 2/30\n",
            "4164/4164 [==============================] - 2s 506us/step - loss: 6.7410 - acc: 0.0947 - val_loss: 6.8209 - val_acc: 0.0908\n",
            "\n",
            "Epoch 00002: val_loss improved from 6.91614 to 6.82092, saving model to model_translate.h1\n",
            "Epoch 3/30\n",
            "4164/4164 [==============================] - 2s 508us/step - loss: 6.6343 - acc: 0.0984 - val_loss: 6.7549 - val_acc: 0.0944\n",
            "\n",
            "Epoch 00003: val_loss improved from 6.82092 to 6.75490, saving model to model_translate.h1\n",
            "Epoch 4/30\n",
            "4164/4164 [==============================] - 2s 504us/step - loss: 6.5841 - acc: 0.0973 - val_loss: 6.7269 - val_acc: 0.0953\n",
            "\n",
            "Epoch 00004: val_loss improved from 6.75490 to 6.72691, saving model to model_translate.h1\n",
            "Epoch 5/30\n",
            "4164/4164 [==============================] - 2s 507us/step - loss: 6.5377 - acc: 0.0988 - val_loss: 6.6793 - val_acc: 0.0977\n",
            "\n",
            "Epoch 00005: val_loss improved from 6.72691 to 6.67928, saving model to model_translate.h1\n",
            "Epoch 6/30\n",
            "4164/4164 [==============================] - 2s 509us/step - loss: 6.4996 - acc: 0.0974 - val_loss: 6.6613 - val_acc: 0.0980\n",
            "\n",
            "Epoch 00006: val_loss improved from 6.67928 to 6.66133, saving model to model_translate.h1\n",
            "Epoch 7/30\n",
            "4164/4164 [==============================] - 2s 513us/step - loss: 6.4835 - acc: 0.0962 - val_loss: 6.6511 - val_acc: 0.0964\n",
            "\n",
            "Epoch 00007: val_loss improved from 6.66133 to 6.65111, saving model to model_translate.h1\n",
            "Epoch 8/30\n",
            "4164/4164 [==============================] - 2s 505us/step - loss: 6.3898 - acc: 0.1014 - val_loss: 6.7311 - val_acc: 0.0947\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 6.65111\n",
            "Epoch 9/30\n",
            "4164/4164 [==============================] - 2s 502us/step - loss: 6.3797 - acc: 0.0999 - val_loss: 6.6142 - val_acc: 0.0893\n",
            "\n",
            "Epoch 00009: val_loss improved from 6.65111 to 6.61418, saving model to model_translate.h1\n",
            "Epoch 10/30\n",
            "4164/4164 [==============================] - 2s 511us/step - loss: 6.3596 - acc: 0.0991 - val_loss: 6.5788 - val_acc: 0.0982\n",
            "\n",
            "Epoch 00010: val_loss improved from 6.61418 to 6.57877, saving model to model_translate.h1\n",
            "Epoch 11/30\n",
            "4164/4164 [==============================] - 2s 508us/step - loss: 6.2746 - acc: 0.1026 - val_loss: 6.5177 - val_acc: 0.0995\n",
            "\n",
            "Epoch 00011: val_loss improved from 6.57877 to 6.51772, saving model to model_translate.h1\n",
            "Epoch 12/30\n",
            "4164/4164 [==============================] - 2s 513us/step - loss: 6.2287 - acc: 0.1033 - val_loss: 6.4862 - val_acc: 0.1016\n",
            "\n",
            "Epoch 00012: val_loss improved from 6.51772 to 6.48616, saving model to model_translate.h1\n",
            "Epoch 13/30\n",
            "4164/4164 [==============================] - 2s 513us/step - loss: 6.2182 - acc: 0.1018 - val_loss: 6.4929 - val_acc: 0.0999\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 6.48616\n",
            "Epoch 14/30\n",
            "4164/4164 [==============================] - 2s 508us/step - loss: 6.1592 - acc: 0.1039 - val_loss: 6.4709 - val_acc: 0.1007\n",
            "\n",
            "Epoch 00014: val_loss improved from 6.48616 to 6.47091, saving model to model_translate.h1\n",
            "Epoch 15/30\n",
            "4164/4164 [==============================] - 2s 518us/step - loss: 6.1170 - acc: 0.1038 - val_loss: 6.4108 - val_acc: 0.1012\n",
            "\n",
            "Epoch 00015: val_loss improved from 6.47091 to 6.41081, saving model to model_translate.h1\n",
            "Epoch 16/30\n",
            "4164/4164 [==============================] - 2s 505us/step - loss: 6.0546 - acc: 0.1047 - val_loss: 6.3303 - val_acc: 0.1035\n",
            "\n",
            "Epoch 00016: val_loss improved from 6.41081 to 6.33026, saving model to model_translate.h1\n",
            "Epoch 17/30\n",
            "4164/4164 [==============================] - 2s 505us/step - loss: 6.0403 - acc: 0.1041 - val_loss: 6.3119 - val_acc: 0.1024\n",
            "\n",
            "Epoch 00017: val_loss improved from 6.33026 to 6.31195, saving model to model_translate.h1\n",
            "Epoch 18/30\n",
            "4164/4164 [==============================] - 2s 514us/step - loss: 5.9800 - acc: 0.1051 - val_loss: 6.3184 - val_acc: 0.1016\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 6.31195\n",
            "Epoch 19/30\n",
            "4164/4164 [==============================] - 2s 503us/step - loss: 5.9293 - acc: 0.1054 - val_loss: 6.2496 - val_acc: 0.1023\n",
            "\n",
            "Epoch 00019: val_loss improved from 6.31195 to 6.24957, saving model to model_translate.h1\n",
            "Epoch 20/30\n",
            "4164/4164 [==============================] - 2s 511us/step - loss: 5.8994 - acc: 0.1058 - val_loss: 6.2532 - val_acc: 0.1039\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 6.24957\n",
            "Epoch 21/30\n",
            "4164/4164 [==============================] - 2s 510us/step - loss: 5.8542 - acc: 0.1053 - val_loss: 6.2045 - val_acc: 0.1058\n",
            "\n",
            "Epoch 00021: val_loss improved from 6.24957 to 6.20446, saving model to model_translate.h1\n",
            "Epoch 22/30\n",
            "4164/4164 [==============================] - 2s 511us/step - loss: 5.8023 - acc: 0.1069 - val_loss: 6.2565 - val_acc: 0.0949\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 6.20446\n",
            "Epoch 23/30\n",
            "4164/4164 [==============================] - 2s 508us/step - loss: 5.7798 - acc: 0.1059 - val_loss: 6.1492 - val_acc: 0.1060\n",
            "\n",
            "Epoch 00023: val_loss improved from 6.20446 to 6.14925, saving model to model_translate.h1\n",
            "Epoch 24/30\n",
            "4164/4164 [==============================] - 2s 507us/step - loss: 5.7209 - acc: 0.1082 - val_loss: 6.1052 - val_acc: 0.1055\n",
            "\n",
            "Epoch 00024: val_loss improved from 6.14925 to 6.10520, saving model to model_translate.h1\n",
            "Epoch 25/30\n",
            "4164/4164 [==============================] - 2s 506us/step - loss: 5.7045 - acc: 0.1078 - val_loss: 6.0644 - val_acc: 0.1066\n",
            "\n",
            "Epoch 00025: val_loss improved from 6.10520 to 6.06438, saving model to model_translate.h1\n",
            "Epoch 26/30\n",
            "4164/4164 [==============================] - 2s 505us/step - loss: 5.6037 - acc: 0.1105 - val_loss: 6.1355 - val_acc: 0.1027\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 6.06438\n",
            "Epoch 27/30\n",
            "4164/4164 [==============================] - 2s 515us/step - loss: 5.6311 - acc: 0.1117 - val_loss: 6.0096 - val_acc: 0.1078\n",
            "\n",
            "Epoch 00027: val_loss improved from 6.06438 to 6.00956, saving model to model_translate.h1\n",
            "Epoch 28/30\n",
            "4164/4164 [==============================] - 2s 506us/step - loss: 5.5394 - acc: 0.1127 - val_loss: 6.0155 - val_acc: 0.1054\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 6.00956\n",
            "Epoch 29/30\n",
            "4164/4164 [==============================] - 2s 518us/step - loss: 5.4867 - acc: 0.1133 - val_loss: 5.9991 - val_acc: 0.1060\n",
            "\n",
            "Epoch 00029: val_loss improved from 6.00956 to 5.99912, saving model to model_translate.h1\n",
            "Epoch 30/30\n",
            "4164/4164 [==============================] - 2s 516us/step - loss: 5.5011 - acc: 0.1135 - val_loss: 5.9119 - val_acc: 0.1108\n",
            "\n",
            "Epoch 00030: val_loss improved from 5.99912 to 5.91189, saving model to model_translate.h1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwrL0_sjmUuO",
        "colab_type": "text"
      },
      "source": [
        "# 5)-Plotting results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUYdtjQXlupF",
        "colab_type": "code",
        "outputId": "3c720292-d751-44a9-8567-e6152b86434e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.plot(history.history['loss']) \n",
        "plt.plot(history.history['val_loss']) \n",
        "plt.legend(['train','validation']) \n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQVCiaNDn4VJ",
        "colab_type": "text"
      },
      "source": [
        "As you can see in the above plot, the validation loss stopped decreasing after 20 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgePSmZBmSbn",
        "colab_type": "text"
      },
      "source": [
        "# 6)-Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gh_CukCl7Al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('model_translate.h1') \n",
        "\n",
        "preds = model.predict_classes(testX.reshape((testX.shape[0], testX.shape[1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-DaR0x4oA4P",
        "colab_type": "text"
      },
      "source": [
        "These predictions are sequences of integers. We need to convert these integers to their corresponding words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU6IOmOOoB3f",
        "colab_type": "text"
      },
      "source": [
        "### 6.1)- Convert integers to words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiy9gGAAmAat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word(n, tokenizer):  \n",
        "      for word, index in tokenizer.word_index.items():                       \n",
        "          if index == n: \n",
        "              return word \n",
        "      return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqSwZTcXmDTW",
        "colab_type": "text"
      },
      "source": [
        "### 6.2)-Convert predictions into text (English)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y82jlYQMmAg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_text = [] \n",
        "for i in preds:        \n",
        "       temp = []        \n",
        "       for j in range(len(i)):             \n",
        "            t = get_word(i[j], eng_tokenizer)             \n",
        "            if j > 0:                 \n",
        "                if (t==get_word(i[j-1],eng_tokenizer))or(t== None):                       \n",
        "                     temp.append('')                 \n",
        "                else:                      \n",
        "                     temp.append(t)             \n",
        "            else:                    \n",
        "                if(t == None):                                   \n",
        "                     temp.append('')                    \n",
        "                else:                           \n",
        "                     temp.append(t)        \n",
        "       preds_text.append(' '.join(temp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOAI5cB8mAj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2orsrv6oo4o",
        "colab_type": "code",
        "outputId": "31e48e88-1ac6-4d31-8cb6-2d23290f9155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "# 1st 15 rows\n",
        "pred_df.head(15)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>as competitors circle ever closer and new technology challenges cosy old certainties the imminent negotiation of the licence fee is fraught with especial danger for the bbc</td>\n",
              "      <td>the and the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>luther rabinowitz collapsed his pyramid</td>\n",
              "      <td>i  in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the health authorities recently explained that the disease has reached all corners of the country</td>\n",
              "      <td>the to   the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i do not condone the tweet and i have taken it down the later post said</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>for the manager of the oberursel cult kiosk taking part in cycling events which go over the feldberg is perfectly natural</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>nato will not break their agreements with russian as a result of their planned deployment to east europe in response to the ukrainian crisis</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>another one who enjoyed himself was frittentoni</td>\n",
              "      <td>i was is the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>the billion cruise industry is expected to benefit in the coming years from the rise of the middle class in emerging economies such as china and india</td>\n",
              "      <td>the and to and the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>in addition to this the separatists reported that they have taken control of several towns and villages in the donezk region</td>\n",
              "      <td>the and to and the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>kiev and moscow have agreed to new talks on gas</td>\n",
              "      <td>to and    the  to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>many friends and neighbours were killed in the siege and it only adds to my pain</td>\n",
              "      <td>but and    to  him</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>his dad vladimir who scooped up his son outside said damir told me his mother had died</td>\n",
              "      <td>but that  and  to  it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>perry vetoed funds to her office when she refused to resign which led to a grand jury in austin this month indicting perry who is a potential presidential candidate</td>\n",
              "      <td>the and to and a the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>they were fed and watered on their way back in havixbeck and billerbeck</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>she is a supporter of pipeline south stream run by the russian firm gasprom through which russian natural gas is to be transported directly to southern europe bypassing ukraine this will also make...</td>\n",
              "      <td>and  to   in to said</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                     actual               predicted\n",
              "0                              as competitors circle ever closer and new technology challenges cosy old certainties the imminent negotiation of the licence fee is fraught with especial danger for the bbc        the and the     \n",
              "1                                                                                                                                                                   luther rabinowitz collapsed his pyramid              i  in     \n",
              "2                                                                                                         the health authorities recently explained that the disease has reached all corners of the country         the to   the   \n",
              "3                                                                                                                                   i do not condone the tweet and i have taken it down the later post said              the       \n",
              "4                                                                                 for the manager of the oberursel cult kiosk taking part in cycling events which go over the feldberg is perfectly natural              the       \n",
              "5                                                              nato will not break their agreements with russian as a result of their planned deployment to east europe in response to the ukrainian crisis              the       \n",
              "6                                                                                                                                                           another one who enjoyed himself was frittentoni        i was is the    \n",
              "7                                                    the billion cruise industry is expected to benefit in the coming years from the rise of the middle class in emerging economies such as china and india   the and to and the   \n",
              "8                                                                              in addition to this the separatists reported that they have taken control of several towns and villages in the donezk region   the and to and the   \n",
              "9                                                                                                                                                           kiev and moscow have agreed to new talks on gas       to and    the  to\n",
              "10                                                                                                                         many friends and neighbours were killed in the siege and it only adds to my pain      but and    to  him\n",
              "11                                                                                                                   his dad vladimir who scooped up his son outside said damir told me his mother had died   but that  and  to  it\n",
              "12                                     perry vetoed funds to her office when she refused to resign which led to a grand jury in austin this month indicting perry who is a potential presidential candidate  the and to and a the  \n",
              "13                                                                                                                                  they were fed and watered on their way back in havixbeck and billerbeck              the       \n",
              "14  she is a supporter of pipeline south stream run by the russian firm gasprom through which russian natural gas is to be transported directly to southern europe bypassing ukraine this will also make...    and  to   in to said"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPocsO00mJy-",
        "colab_type": "code",
        "outputId": "d6e39bf1-5363-4e52-97bd-32ffe453a560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        }
      },
      "source": [
        "# print 15 rows randomly \n",
        "pred_df.sample(15)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1105</th>\n",
              "      <td>businesses state and local tax burdens last year expanded by percent to billion compared with percent the year before and it was the third consecutive year of growth after backtoback years of shri...</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1112</th>\n",
              "      <td>a woman has been hospitalised after screaming so hard during the ice bucket challenge that she dislocated her jaw</td>\n",
              "      <td>but my  and  to  it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>823</th>\n",
              "      <td>i now know that i can do it brilliant</td>\n",
              "      <td>i that to     it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>on the israeli side soldiers and six civilians including a thai worker were killed</td>\n",
              "      <td>and     in  said</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>no one it seems can be sure that they are safe</td>\n",
              "      <td>and     in to said</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>807</th>\n",
              "      <td>we havent been playing as badly in recent weeks as it has been made out to be</td>\n",
              "      <td>and that to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1086</th>\n",
              "      <td>he was another one who did it all in one go as did nina kuhn press spokesperson for the oberursel council who did the route along side frank gruneisen</td>\n",
              "      <td>to and to  a the  to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1296</th>\n",
              "      <td>in one of abbotts patients arrived at his gps surgery with similar symptoms to him and was subsequently diagnosed with mesothelioma</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>673</th>\n",
              "      <td>the first day back at school is traditionally celebrated by children wearing embroidered shirts carrying balloons and giving flowers to their teachers</td>\n",
              "      <td>to and    in  to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1279</th>\n",
              "      <td>the hessian spd chairman thorsten schafergumbel who led the german delegation said to the host that he would keeps his ears open in germany for a possible partner</td>\n",
              "      <td>the and to  the   said</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>861</th>\n",
              "      <td>after registering at the fraternitys club house sta</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>now the two are coming together there should soon be talks about a joint venture</td>\n",
              "      <td>to and to and  in the to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>one person who has never been able to pinpoint his exposure to asbestos is graham abbott a gp</td>\n",
              "      <td>the  to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>903</th>\n",
              "      <td>his crew chief chad johnston said the team was disappointed but will now start focusing on next weekends race in richmond virginia</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>harburg tents for new refugees</td>\n",
              "      <td>the was is to</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                       actual                 predicted\n",
              "1105  businesses state and local tax burdens last year expanded by percent to billion compared with percent the year before and it was the third consecutive year of growth after backtoback years of shri...                the       \n",
              "1112                                                                                        a woman has been hospitalised after screaming so hard during the ice bucket challenge that she dislocated her jaw       but my  and  to  it\n",
              "823                                                                                                                                                                     i now know that i can do it brilliant          i that to     it\n",
              "117                                                                                                                        on the israeli side soldiers and six civilians including a thai worker were killed          and     in  said\n",
              "260                                                                                                                                                            no one it seems can be sure that they are safe        and     in to said\n",
              "807                                                                                                                             we havent been playing as badly in recent weeks as it has been made out to be          and that to     \n",
              "1086                                                   he was another one who did it all in one go as did nina kuhn press spokesperson for the oberursel council who did the route along side frank gruneisen      to and to  a the  to\n",
              "1296                                                                      in one of abbotts patients arrived at his gps surgery with similar symptoms to him and was subsequently diagnosed with mesothelioma                the       \n",
              "673                                                    the first day back at school is traditionally celebrated by children wearing embroidered shirts carrying balloons and giving flowers to their teachers          to and    in  to\n",
              "1279                                       the hessian spd chairman thorsten schafergumbel who led the german delegation said to the host that he would keeps his ears open in germany for a possible partner    the and to  the   said\n",
              "861                                                                                                                                                       after registering at the fraternitys club house sta                the       \n",
              "31                                                                                                                           now the two are coming together there should soon be talks about a joint venture  to and to and  in the to\n",
              "513                                                                                                             one person who has never been able to pinpoint his exposure to asbestos is graham abbott a gp              the  to     \n",
              "903                                                                        his crew chief chad johnston said the team was disappointed but will now start focusing on next weekends race in richmond virginia                the       \n",
              "492                                                                                                                                                                            harburg tents for new refugees         the was is to    "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    }
  ]
}