{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_t3V5W67K5zX"
   },
   "source": [
    "# Machine Translation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Q5A1ySzLPrq"
   },
   "source": [
    "# 1)- Importing key modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dPBH2WUkKwz-"
   },
   "outputs": [],
   "source": [
    "#support both Python 2 and Python 3 with minimal overhead.\n",
    "from __future__ import absolute_import, division, print_function\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>body {\n",
       "    margin: 0;\n",
       "    font-family: Helvetica;\n",
       "}\n",
       "table.dataframe {\n",
       "    border-collapse: collapse;\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe tr {\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe td, table.dataframe th {\n",
       "    margin: 0;\n",
       "    border: 1px solid white;\n",
       "    padding-left: 0.25em;\n",
       "    padding-right: 0.25em;\n",
       "}\n",
       "table.dataframe th:not(:empty) {\n",
       "    background-color: #fec;\n",
       "    text-align: left;\n",
       "    font-weight: normal;\n",
       "}\n",
       "table.dataframe tr:nth-child(2) th:empty {\n",
       "    border-left: none;\n",
       "    border-right: 1px dashed #888;\n",
       "}\n",
       "table.dataframe td {\n",
       "    border: 2px solid #ccf;\n",
       "    background-color: #f4f4ff;\n",
       "}\n",
       "h3 {\n",
       "    color: white;\n",
       "    background-color: black;\n",
       "    padding: 0.5em;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's life without style :). So, let's add style to our dataframes\n",
    "from IPython.core.display import HTML\n",
    "css = open('style-table.css').read() + open('style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zTJY_mj6K-LS"
   },
   "outputs": [],
   "source": [
    "import string \n",
    "from string import digits\n",
    "from collections import Counter\n",
    "import re \n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd \n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "from unicodedata import normalize\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.6.3 64bit [MSC v.1900 64 bit (AMD64)]"
        },
        {
         "module": "IPython",
         "version": "7.4.0"
        },
        {
         "module": "OS",
         "version": "Windows 10 10.0.16299 SP0"
        },
        {
         "module": "pandas",
         "version": "0.23.4"
        },
        {
         "module": "re",
         "version": "2.2.1"
        },
        {
         "module": "sklearn",
         "version": "0.20.3"
        },
        {
         "module": "matplotlib",
         "version": "2.1.0"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.3 64bit [MSC v.1900 64 bit (AMD64)]</td></tr><tr><td>IPython</td><td>7.4.0</td></tr><tr><td>OS</td><td>Windows 10 10.0.16299 SP0</td></tr><tr><td>pandas</td><td>0.23.4</td></tr><tr><td>re</td><td>2.2.1</td></tr><tr><td>sklearn</td><td>0.20.3</td></tr><tr><td>matplotlib</td><td>2.1.0</td></tr><tr><td colspan='2'>Tue Sep 10 16:58:15 2019 W. Europe Daylight Time</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.6.3 64bit [MSC v.1900 64 bit (AMD64)] \\\\ \\hline\n",
       "IPython & 7.4.0 \\\\ \\hline\n",
       "OS & Windows 10 10.0.16299 SP0 \\\\ \\hline\n",
       "pandas & 0.23.4 \\\\ \\hline\n",
       "re & 2.2.1 \\\\ \\hline\n",
       "sklearn & 0.20.3 \\\\ \\hline\n",
       "matplotlib & 2.1.0 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Tue Sep 10 16:58:15 2019 W. Europe Daylight Time} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.6.3 64bit [MSC v.1900 64 bit (AMD64)]\n",
       "IPython 7.4.0\n",
       "OS Windows 10 10.0.16299 SP0\n",
       "pandas 0.23.4\n",
       "re 2.2.1\n",
       "sklearn 0.20.3\n",
       "matplotlib 2.1.0\n",
       "Tue Sep 10 16:58:15 2019 W. Europe Daylight Time"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first install: pip install version_information\n",
    "%reload_ext version_information\n",
    "%version_information pandas,re,sklearn, matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-X0sC5fLS7a"
   },
   "source": [
    "# 2)- Loading data\n",
    "\n",
    "We have data from 2009 to 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFpuPSdKLEtJ"
   },
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3QpycswrLlaU"
   },
   "outputs": [],
   "source": [
    "# split a loaded document into sentences\n",
    "def to_sentences(doc):\n",
    "\treturn doc.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GMLe1Lk5LnAV"
   },
   "outputs": [],
   "source": [
    "# shortest and longest sentence lengths\n",
    "def sentence_lengths(sentences):\n",
    "\tlengths = [len(s.split()) for s in sentences]\n",
    "\treturn min(lengths), max(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lkrmOs7-L0X0"
   },
   "source": [
    "### 2.1)- For year 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Xg8f11ToLpnc",
    "outputId": "311de7c7-f649-42f0-8cd9-ec431b5807f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=2525, min=1, max=108\n",
      "German data: sentences=2525, min=1, max=110\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2009.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load German data\n",
    "filename = 'newstest2009.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQmRuUHGL74N"
   },
   "source": [
    "It is important to notice that sentence length is same. So, we have a balanced data.\n",
    "\n",
    "We shall check this on all years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lr3hYKrBMGtQ"
   },
   "source": [
    "### 2.2)-For 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "bF2HZBV-LycJ",
    "outputId": "acdf8664-6604-4301-8d9d-ba390eaf4347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=2489, min=1, max=74\n",
      "German data: sentences=2489, min=1, max=86\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2010.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load german data\n",
    "filename = 'newstest2010.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xFaKT4WENIA0"
   },
   "source": [
    "### 2.3)-For year 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "OFdlOFxaM8GF",
    "outputId": "36ee1165-5d13-4dab-84dc-23b0f15cf953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=3003, min=1, max=93\n",
      "German data: sentences=3003, min=1, max=92\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2011.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load German data\n",
    "filename = 'newstest2011.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-iKcf42NQl9"
   },
   "source": [
    "### 2.4)-For year 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "T6YRzm6yNO12",
    "outputId": "9b944f1f-774e-458a-9039-0ccffa67ab29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=3003, min=1, max=114\n",
      "German data: sentences=3003, min=1, max=101\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2012.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load German data\n",
    "filename = 'newstest2012.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4624P_5XNUCW"
   },
   "source": [
    "### 2.5)-For year 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6pqUQn_dNW8B",
    "outputId": "b7324f03-847e-44b7-9548-e0a01f752c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=3000, min=1, max=82\n",
      "German data: sentences=3000, min=1, max=85\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2013.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load German data\n",
    "filename = 'newstest2013.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ROs3kgYNXzl"
   },
   "source": [
    "### 2.6)-For year 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "ZlS9fS1ANcTU",
    "outputId": "b6621ab2-a139-465e-96ce-f3f0fe6040bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=3003, min=1, max=68\n",
      "German data: sentences=3003, min=1, max=64\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2014.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load German data\n",
    "filename = 'newstest2014.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_By95YGUOKjP"
   },
   "source": [
    "### 2.7)- For year 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Id289Xi1ONBv",
    "outputId": "d7d9604d-c494-4b87-b9c8-47cc10ba9d87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=2169, min=1, max=71\n",
      "German data: sentences=2169, min=1, max=72\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2015.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load German data\n",
    "filename = 'newstest2015.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VzgjV6OjON2G"
   },
   "source": [
    "### For year 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "z2fUwxLLOQFR",
    "outputId": "53495f34-d4a9-4c63-a113-e531e115c426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=2999, min=1, max=83\n",
      "German data: sentences=2999, min=1, max=88\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2016.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load German data\n",
    "filename = 'newstest2016.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Jlgba1dOkje"
   },
   "source": [
    "**All datasets have balanced sentences for English and German version**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "351hNk4lOsGe"
   },
   "source": [
    "# 3)- Data Cleaning\n",
    "\n",
    "- Tokenizing text by white space.\n",
    "- Normalizing case to lowercase.\n",
    "- Removing punctuation from each word.\n",
    "- Removing non-printable characters.\n",
    "- Removing words that contain non-alphabetic characters.\n",
    "\n",
    "\n",
    "**We shall use only one file(2015) for quick processing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4XeL-PkOh7o"
   },
   "outputs": [],
   "source": [
    "# create cleaning function\n",
    "\n",
    "def clean_lines(lines):\n",
    "\tcleaned = list()\n",
    "\t# prepare regex for char filtering\n",
    "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "\t# prepare translation table for removing punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\tfor line in lines:\n",
    "\t\t# normalize unicode characters\n",
    "\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "\t\tline = line.decode('UTF-8')\n",
    "\t\t# tokenize on white space\n",
    "\t\tline = line.split()\n",
    "\t\t# convert to lower case\n",
    "\t\tline = [word.lower() for word in line]\n",
    "\t\t# remove punctuation from each token\n",
    "\t\tline = [word.translate(table) for word in line]\n",
    "\t\t# remove non-printable chars form each token\n",
    "\t\tline = [re_print.sub('', w) for w in line]\n",
    "\t\t# remove tokens with numbers in them\n",
    "\t\tline = [word for word in line if word.isalpha()]\n",
    "\t\t# store as string\n",
    "\t\tcleaned.append(' '.join(line))\n",
    "\treturn cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXXFMVdbQIIs"
   },
   "outputs": [],
   "source": [
    "# save a list of clean sentences to file\n",
    "def save_clean_sentences(sentences, filename):\n",
    "\tdump(sentences, open(filename, 'wb'))\n",
    "\tprint('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uaYHZmrgQMJ0",
    "outputId": "2e3c9597-9a43-4c9f-f9b9-a577c0f73775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english2015.pkl\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2015.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'english2015.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "id": "Tb9xfJXJQeGX",
    "outputId": "9b1244e5-8d65-4cad-cc09-be937c555f71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india and japan prime ministers meet in tokyo\n",
      "indias new prime minister narendra modi is meeting his japanese counterpart shinzo abe in tokyo to discuss economic and security ties on his first major foreign visit since winning mays election\n",
      "mr modi is on a fiveday trip to japan to strengthen economic ties with the third largest economy in the world\n",
      "high on the agenda are plans for greater nuclear cooperation\n",
      "india is also reportedly hoping for a deal on defence collaboration between the two nations\n",
      "karratha police arrest after high speed motorcycle chase\n",
      "a motorcycle has been seized after it was ridden at in a zone and through bushland to escape police in the pilbara\n",
      "traffic police on patrol in karratha this morning tried to pull over a blue motorcycle when they spotted it reaching as it pulled out of a service station on bathgate road\n",
      "police say the rider then failed to stop and continued on to burgess road before turning into bushland causing the officers to lose sight of it\n",
      "the motorcycle and a person matching the description of the rider was then spotted at a house on walcott way in bulgarra\n"
     ]
    }
   ],
   "source": [
    "# spot check for english version\n",
    "for i in range(10):\n",
    "\tprint(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "Wryy3Y1OQVDv",
    "outputId": "67adf2b8-d1a3-4b46-9715-d5d04f40f3ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: german2015.pkl\n",
      "die premierminister indiens und japans trafen sich in tokio\n",
      "indiens neuer premierminister narendra modi trifft bei seinem ersten wichtigen auslandsbesuch seit seinem wahlsieg im mai seinen japanischen amtskollegen shinzo abe in toko um wirtschaftliche und sicherheitspolitische beziehungen zu besprechen\n",
      "herr modi befindet sich auf einer funftagigen reise nach japan um die wirtschaftlichen beziehungen mit der drittgroten wirtschaftsnation der welt zu festigen\n",
      "plane fur eine starkere kerntechnische zusammenarbeit stehen ganz oben auf der tagesordnung\n",
      "berichten zufolge hofft indien daruber hinaus auf einen vertrag zur verteidigungszusammenarbeit zwischen den beiden nationen\n",
      "polizei von karratha verhaftet nach schneller motorradjagd\n",
      "ein motorrad wurde beschlagnahmt nachdem der fahrer es mit kmh in einer kmhzone und durch buschland gefahren hatte um der polizei in bilbara zu entkommen\n",
      "verkehrspolizisten in karratha versuchten heute morgen ein blaues motorrad zu stoppen nachdem sie es dabei beobachtet hatten wie es mit kmh eine tankstelle auf der bathdate road verlie\n",
      "die polizei berichtet dass der fahrer die haltesignale dann ignorierte und weiter auf der burgess road fuhr bevor er in das buschland abbog wo die beamten es aus den augen verloren\n",
      "das motorrad sowie eine person die der beschreibung des fahrers entsprach wurden spater bei einem haus im walcott way in bulgarra gesehen\n"
     ]
    }
   ],
   "source": [
    "# load and check German data\n",
    "\n",
    "filename = 'newstest2015.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'german2015.pkl')\n",
    "# spot check for german version\n",
    "for i in range(10):\n",
    "\tprint(sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jtx8CoZTRmG4"
   },
   "source": [
    "# 4)- Checking Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLX2pg3KTqlB"
   },
   "outputs": [],
   "source": [
    "# function to load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "\treturn load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6iYQaotVRaZ"
   },
   "outputs": [],
   "source": [
    "# function to save a list of clean sentences to file\n",
    "def save_clean_sentences(sentences, filename):\n",
    "\tdump(sentences, open(filename, 'wb'))\n",
    "\tprint('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_RVdnLCSCuo"
   },
   "source": [
    "### 4.1)-frequency table\n",
    "create a frequency table for all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "icBWdxApRJyv"
   },
   "outputs": [],
   "source": [
    "def to_vocab(lines):\n",
    "\tvocab = Counter()\n",
    "\tfor line in lines:\n",
    "\t\ttokens = line.split()\n",
    "\t\tvocab.update(tokens)\n",
    "\treturn vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LQIVl-zSSQdO"
   },
   "source": [
    "### 4.2)- Trim Vocab\n",
    "\n",
    "Process the created vocabulary and remove all words from the Counter that have an occurrence below a specific threshold using *out of vocabulary (OOV)* method.\n",
    "\n",
    "\n",
    "https://medium.com/@shabeelkandi/handling-out-of-vocabulary-words-in-natural-language-processing-based-on-context-4bbba16214d5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iBqCUzMPSbn4"
   },
   "outputs": [],
   "source": [
    "def trim_vocab(vocab, min_occurance):\n",
    "\ttokens = [k for k,c in vocab.items() if c >= min_occurance]\n",
    "\treturn set(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctXFtetOSjsf"
   },
   "source": [
    "### 4.3)- Update dataset\n",
    "\n",
    "Update the sentences, remove all words not in the trimmed vocabulary and mark their removal with a special token, in this case, the string “unk“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fymy1xb5Sf_a"
   },
   "outputs": [],
   "source": [
    "def update_dataset(lines, vocab):\n",
    "\tnew_lines = list()\n",
    "\tfor line in lines:\n",
    "\t\tnew_tokens = list()\n",
    "\t\tfor token in line.split():\n",
    "\t\t\tif token in vocab:\n",
    "\t\t\t\tnew_tokens.append(token)\n",
    "\t\t\telse:\n",
    "\t\t\t\tnew_tokens.append('unk')\n",
    "\t\tnew_line = ' '.join(new_tokens)\n",
    "\t\tnew_lines.append(new_line)\n",
    "\treturn new_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qfg7hEWQTApL"
   },
   "source": [
    "### 4.4)- Check English version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "Hs6lDK3RUZFR",
    "outputId": "59e23cf3-b0af-4f99-d35a-1813c72c8f00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary: 7227\n",
      "New English Vocabulary: 1210\n",
      "Saved: english_vocab2015.pkl\n"
     ]
    }
   ],
   "source": [
    "# load English dataset i.e pickled earlier\n",
    "filename = 'english2015.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "\n",
    "# calculate vocabulary\n",
    "vocab = to_vocab(lines)\n",
    "print('English Vocabulary: %d' % len(vocab))\n",
    "\n",
    "# reduce vocabulary\n",
    "vocab = trim_vocab(vocab, 5)\n",
    "print('New English Vocabulary: %d' % len(vocab))\n",
    "\n",
    "# mark out of vocabulary words\n",
    "lines = update_dataset(lines, vocab)\n",
    "# save updated dataset\n",
    "filename = 'english_vocab2015.pkl'\n",
    "save_clean_sentences(lines, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6A4kJkxAW79J"
   },
   "source": [
    "### 4.5)-Check German version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "zv3bZhbTUyPl",
    "outputId": "235a6d72-0425-4fe9-98f6-9df8e31f2312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German Vocabulary: 9280\n",
      "New German Vocabulary: 988\n",
      "Saved: german_vocab2015.pkl\n"
     ]
    }
   ],
   "source": [
    "# load English dataset i.e pickled earlier\n",
    "filename = 'german2015.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "\n",
    "# calculate vocabulary\n",
    "vocab = to_vocab(lines)\n",
    "print('German Vocabulary: %d' % len(vocab))\n",
    "\n",
    "# reduce vocabulary\n",
    "vocab = trim_vocab(vocab, 5)\n",
    "print('New German Vocabulary: %d' % len(vocab))\n",
    "\n",
    "# mark out of vocabulary words\n",
    "lines = update_dataset(lines, vocab)\n",
    "# save updated dataset\n",
    "filename = 'german_vocab2015.pkl'\n",
    "save_clean_sentences(lines, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y1ZW_PsfXOc8"
   },
   "source": [
    "These cleaning and vocab reduction methods have given us a more normalized and potent data for model training"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Preprocess.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
