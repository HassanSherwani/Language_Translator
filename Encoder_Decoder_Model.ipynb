{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Encoder-Decoder-Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QJxJLfT6m4zo"
      },
      "source": [
        "# Machine Translation\n",
        "\n",
        "English-German Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YvFSu3KOnCQI"
      },
      "source": [
        "# 1)- Importing key modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ydSdCo4JzRta",
        "colab": {}
      },
      "source": [
        "#support both Python 2 and Python 3 with minimal overhead.\n",
        "from __future__ import absolute_import, division, print_function\n",
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXS6Ad_pwdsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What's life without style :). So, let's add style to our dataframes\n",
        "#from IPython.core.display import HTML\n",
        "#css = open('style-table.css').read() + open('style-notebook.css').read()\n",
        "#HTML('<style>{}</style>'.format(css))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HXdjBXc-zNXe",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import string \n",
        "import pickle\n",
        "from pickle import dump\n",
        "from pickle import load\n",
        "from string import digits\n",
        "import re \n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import array, argmax, random, take \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline \n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ElRcz5K3hJrC",
        "outputId": "0a4ed255-3e48-48f9-c0da-8fd62a5d9435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, LSTM, Embedding,Input,RepeatVector\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model \n",
        "from keras import optimizers "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI5oZH-mwmWL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16a8bd03-65d9-4282-83e0-e3bfed74bc7a"
      },
      "source": [
        "!  pip install version_information"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: version_information in /usr/local/lib/python3.6/dist-packages (1.0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91NCx_C7wdsZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "96b2e977-c242-4494-f77a-c467955c0a9f"
      },
      "source": [
        "# first install: pip install version_information\n",
        "%reload_ext version_information\n",
        "%version_information pandas,re,sklearn, matplotlib,keras"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/latex": "\\begin{tabular}{|l|l|}\\hline\n{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\nPython & 3.6.8 64bit [GCC 8.0.1 20180414 (experimental) [trunk revision 259383] \\\\ \\hline\nIPython & 5.5.0 \\\\ \\hline\nOS & Linux 4.14.137+ x86\\_64 with Ubuntu 18.04 bionic \\\\ \\hline\npandas & 0.24.2 \\\\ \\hline\nre & 2.2.1 \\\\ \\hline\nsklearn & 0.21.3 \\\\ \\hline\nmatplotlib & 3.0.3 \\\\ \\hline\nkeras & 2.2.5 \\\\ \\hline\n\\hline \\multicolumn{2}{|l|}{Tue Sep 10 15:40:12 2019 UTC} \\\\ \\hline\n\\end{tabular}\n",
            "application/json": {
              "Software versions": [
                {
                  "version": "3.6.8 64bit [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]",
                  "module": "Python"
                },
                {
                  "version": "5.5.0",
                  "module": "IPython"
                },
                {
                  "version": "Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic",
                  "module": "OS"
                },
                {
                  "version": "0.24.2",
                  "module": "pandas"
                },
                {
                  "version": "2.2.1",
                  "module": "re"
                },
                {
                  "version": "0.21.3",
                  "module": "sklearn"
                },
                {
                  "version": "3.0.3",
                  "module": "matplotlib"
                },
                {
                  "version": "2.2.5",
                  "module": "keras"
                }
              ]
            },
            "text/html": [
              "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.8 64bit [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]</td></tr><tr><td>IPython</td><td>5.5.0</td></tr><tr><td>OS</td><td>Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic</td></tr><tr><td>pandas</td><td>0.24.2</td></tr><tr><td>re</td><td>2.2.1</td></tr><tr><td>sklearn</td><td>0.21.3</td></tr><tr><td>matplotlib</td><td>3.0.3</td></tr><tr><td>keras</td><td>2.2.5</td></tr><tr><td colspan='2'>Tue Sep 10 15:40:12 2019 UTC</td></tr></table>"
            ],
            "text/plain": [
              "Software versions\n",
              "Python 3.6.8 64bit [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]\n",
              "IPython 5.5.0\n",
              "OS Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic\n",
              "pandas 0.24.2\n",
              "re 2.2.1\n",
              "sklearn 0.21.3\n",
              "matplotlib 3.0.3\n",
              "keras 2.2.5\n",
              "Tue Sep 10 15:40:12 2019 UTC"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XN_b91atnHye"
      },
      "source": [
        "# 2)- Reading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZM1ZO53WhL_6",
        "colab": {}
      },
      "source": [
        "lines= pd.read_pickle('full_data.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gws8XMBx-IfV",
        "outputId": "9a624227-9cbc-4cef-a147-8b272a2d1cdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lines.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22191, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GdbfP26dHHIX",
        "outputId": "0d7dc9f1-3ca7-4574-f6f0-beb9898cd3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "lines.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>ger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Prague Stock Market falls to minus by the end of the trading day</td>\n",
              "      <td>Die Prager Börse stürzt gegen Geschäftsschluss ins Minus.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>After a sharp drop in the morning</td>\n",
              "      <td>Nach dem steilen Abfall am Morgen konnte die Prager Börse die Verluste korrigieren.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Transactions with stocks from the Czech Energy Enterprise (ČEZ) reached nearly half of the regular daily trading.</td>\n",
              "      <td>Die Transaktionen mit den Aktien von ČEZ erreichten fast die Hälfte des normalen Tagesgeschäfts.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Prague Stock Market immediately continued its fall from Monday at the beginning of Tuesday's trading</td>\n",
              "      <td>Die Prager Börse knüpfte gleich zu Beginn der Dienstagsgeschäfte an den Einbruch vom Montag an</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This time the fall in stocks on Wall Street is responsible for the drop.</td>\n",
              "      <td>Diesmal lag der Grund für den Einbruch an der Wall Street.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                 eng                                                                                               ger\n",
              "0                                                   Prague Stock Market falls to minus by the end of the trading day                                         Die Prager Börse stürzt gegen Geschäftsschluss ins Minus.\n",
              "1                                                                                  After a sharp drop in the morning               Nach dem steilen Abfall am Morgen konnte die Prager Börse die Verluste korrigieren.\n",
              "2  Transactions with stocks from the Czech Energy Enterprise (ČEZ) reached nearly half of the regular daily trading.  Die Transaktionen mit den Aktien von ČEZ erreichten fast die Hälfte des normalen Tagesgeschäfts.\n",
              "3           The Prague Stock Market immediately continued its fall from Monday at the beginning of Tuesday's trading    Die Prager Börse knüpfte gleich zu Beginn der Dienstagsgeschäfte an den Einbruch vom Montag an\n",
              "4                                           This time the fall in stocks on Wall Street is responsible for the drop.                                        Diesmal lag der Grund für den Einbruch an der Wall Street."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8532Vnqswdsh",
        "colab_type": "text"
      },
      "source": [
        "As this is big data and I have a poor old computing machine. So, I ll use smaller sample. It got to be random to avoid sample biaseness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZuWRYCZwdsh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "a5abd79a-8f67-4765-d2ad-bd30a97a64fe"
      },
      "source": [
        "lines.sample(15)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>ger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20317</th>\n",
              "      <td>How have residents reacted to your terraced house project?</td>\n",
              "      <td>Wie haben die Anwohner auf ihr Reihenhaus-Projekt reagiert?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11873</th>\n",
              "      <td>Kirill Miller is an outstanding man of the St. Petersburg avant-garde of the late 80's early 90's.</td>\n",
              "      <td>Kirill Miller ist eine leuchtende Persönlichkeit der Petersburger Avantgarde Ende der 80er bzw. Anfang der 90er.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4835</th>\n",
              "      <td>Moreover, Ferrovial, the autonomous government of Castile-La Mancha, and the University of Alcala de Henares signed a protocol of cooperation yesterday to create a Center for the Innovation of Int...</td>\n",
              "      <td>Auf der anderen Seite haben Ferrovial, die Regierung von Kastilien-La Mancha und die Universität von Alcalá de Henares gestern ein Protokoll zur Zusammenarbeit zwecks Schaffung eines Innovationsze...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8256</th>\n",
              "      <td>The idea of changing cars during races is unusual.</td>\n",
              "      <td>Eine ungewöhnliche Idee ist auch der Wagenwechsel im Laufe der Rennen.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4714</th>\n",
              "      <td>The intervention of the aid, however, calls for the full braking system, reducing the distance the car needs to stop.</td>\n",
              "      <td>Die Bremshilfe dagegen greift mit maximaler Kraft in das Bremssystem ein und verringert dadurch die Bremszeit und somit auch den Bremsabstand, den ein Auto beim Bremsvorgang zurücklegt.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20080</th>\n",
              "      <td>A couple of half-centuries and Lyth might have seen his run extended but he was in control of his own destiny.</td>\n",
              "      <td>Vor langer Zeit hätte man den Lauf von Lyth verlängert, aber er hatte die Kontrolle über sein eigenes Schicksal.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14993</th>\n",
              "      <td>In their first three appearances in the European top flight, the Munich team put in a good performance for long periods, but in the crucial phases were not sufficiently focussed.</td>\n",
              "      <td>Bei ihrem erst dritten Auftritt in der europäischen Königsklasse verkauften sich die Münchner lange sehr gut, waren in den entscheidenden Phasen aber einfach nicht abgeklärt genug.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4022</th>\n",
              "      <td>As soon as Frankfurt is blanketed in snow and the temperatures drop below zero, 20 so-called \"A Routes\" are serviced by large-scale distribution vehicles, explains Brauburger.</td>\n",
              "      <td>Sobald es in Frankfurt flächendeckend schneit und die Temperaturen unter Null Grad liegen, werden 20 sogenannte A-Strecken mit Großstreufahrzeugen abgefahren, erläutert Brauburger.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9865</th>\n",
              "      <td>\"She said in an aggressive tone, \"You shouldn't have left your daughter by the door,\"\" Roseanna Monk said.</td>\n",
              "      <td>\"Sie sagte in einem aggressiven Ton: \"Sie sollten Ihre Tochter nicht in der Nähe der Tür absetzen\", sagte Roseanna Monk.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18060</th>\n",
              "      <td>The reason that we are feeling its deadly effects now is that, though asbestos use has been illegal for years (all types of asbestos were eventually banned by law in 1999), it usually takes decade...</td>\n",
              "      <td>Der Grund, warum wir die tödlichen Auswirkungen jetzt erleben, obwohl Asbest seit Jahren illegal ist (1999 wurden alle Asbesttypen verboten), ist der, dass ein Mesotheliom sich erst nach Jahrzehnt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8205</th>\n",
              "      <td>The adventure opens very well.</td>\n",
              "      <td>Das Abenteuer beginnt sehr gut.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>It is the second price increase this year</td>\n",
              "      <td>Es ist der zweite Preisanstieg dieses Jahr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>Just like the exact same price of gasoline at the gas stations is surely just the product of coincidence and the tough competitive battle.</td>\n",
              "      <td>Genauso wie der absolut gleiche Benzinpreis bei den Tankstellen sicher nur Zufall und die Folge eines harten Konkurrenzkampfes ist.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6619</th>\n",
              "      <td>But that is not likely to be the last word on the issue.</td>\n",
              "      <td>Doch das war mit Sicherheit noch nicht das letzte Wort in dieser Sache.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10040</th>\n",
              "      <td>On the national side, with less than 30 presences, there are Roy Miller with 26, Winston Parks with 26, Gabriel Badilla with 25 and Roy Myrie with 23.</td>\n",
              "      <td>Von Seiten der Nationalmannschaft kommen auf weniger als 30 Spiele Roy Miller mit 26, Winston Parks mit 26, Gabriel Badilla mit 25 und Roy Myrie mit 23.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                           eng                                                                                                                                                                                                      ger\n",
              "20317                                                                                                                                               How have residents reacted to your terraced house project?                                                                                                                                              Wie haben die Anwohner auf ihr Reihenhaus-Projekt reagiert?\n",
              "11873                                                                                                       Kirill Miller is an outstanding man of the St. Petersburg avant-garde of the late 80's early 90's.                                                                                         Kirill Miller ist eine leuchtende Persönlichkeit der Petersburger Avantgarde Ende der 80er bzw. Anfang der 90er.\n",
              "4835   Moreover, Ferrovial, the autonomous government of Castile-La Mancha, and the University of Alcala de Henares signed a protocol of cooperation yesterday to create a Center for the Innovation of Int...  Auf der anderen Seite haben Ferrovial, die Regierung von Kastilien-La Mancha und die Universität von Alcalá de Henares gestern ein Protokoll zur Zusammenarbeit zwecks Schaffung eines Innovationsze...\n",
              "8256                                                                                                                                                        The idea of changing cars during races is unusual.                                                                                                                                   Eine ungewöhnliche Idee ist auch der Wagenwechsel im Laufe der Rennen.\n",
              "4714                                                                                     The intervention of the aid, however, calls for the full braking system, reducing the distance the car needs to stop.                Die Bremshilfe dagegen greift mit maximaler Kraft in das Bremssystem ein und verringert dadurch die Bremszeit und somit auch den Bremsabstand, den ein Auto beim Bremsvorgang zurücklegt.\n",
              "20080                                                                                           A couple of half-centuries and Lyth might have seen his run extended but he was in control of his own destiny.                                                                                         Vor langer Zeit hätte man den Lauf von Lyth verlängert, aber er hatte die Kontrolle über sein eigenes Schicksal.\n",
              "14993                       In their first three appearances in the European top flight, the Munich team put in a good performance for long periods, but in the crucial phases were not sufficiently focussed.                     Bei ihrem erst dritten Auftritt in der europäischen Königsklasse verkauften sich die Münchner lange sehr gut, waren in den entscheidenden Phasen aber einfach nicht abgeklärt genug.\n",
              "4022                           As soon as Frankfurt is blanketed in snow and the temperatures drop below zero, 20 so-called \"A Routes\" are serviced by large-scale distribution vehicles, explains Brauburger.                     Sobald es in Frankfurt flächendeckend schneit und die Temperaturen unter Null Grad liegen, werden 20 sogenannte A-Strecken mit Großstreufahrzeugen abgefahren, erläutert Brauburger.\n",
              "9865                                                                                                \"She said in an aggressive tone, \"You shouldn't have left your daughter by the door,\"\" Roseanna Monk said.                                                                                 \"Sie sagte in einem aggressiven Ton: \"Sie sollten Ihre Tochter nicht in der Nähe der Tür absetzen\", sagte Roseanna Monk.\n",
              "18060  The reason that we are feeling its deadly effects now is that, though asbestos use has been illegal for years (all types of asbestos were eventually banned by law in 1999), it usually takes decade...  Der Grund, warum wir die tödlichen Auswirkungen jetzt erleben, obwohl Asbest seit Jahren illegal ist (1999 wurden alle Asbesttypen verboten), ist der, dass ein Mesotheliom sich erst nach Jahrzehnt...\n",
              "8205                                                                                                                                                                            The adventure opens very well.                                                                                                                                                                          Das Abenteuer beginnt sehr gut.\n",
              "847                                                                                                                                                                  It is the second price increase this year                                                                                                                                                               Es ist der zweite Preisanstieg dieses Jahr\n",
              "227                                                                 Just like the exact same price of gasoline at the gas stations is surely just the product of coincidence and the tough competitive battle.                                                                      Genauso wie der absolut gleiche Benzinpreis bei den Tankstellen sicher nur Zufall und die Folge eines harten Konkurrenzkampfes ist.\n",
              "6619                                                                                                                                                  But that is not likely to be the last word on the issue.                                                                                                                                  Doch das war mit Sicherheit noch nicht das letzte Wort in dieser Sache.\n",
              "10040                                                   On the national side, with less than 30 presences, there are Roy Miller with 26, Winston Parks with 26, Gabriel Badilla with 25 and Roy Myrie with 23.                                                 Von Seiten der Nationalmannschaft kommen auf weniger als 30 Spiele Roy Miller mit 26, Winston Parks mit 26, Gabriel Badilla mit 25 und Roy Myrie mit 23."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y11hmIvPFXQi",
        "colab": {}
      },
      "source": [
        "lines = lines[:5000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4sjvE5Nwdsk",
        "colab_type": "text"
      },
      "source": [
        "# 3)- Quick Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GEvO1bfy-KKP",
        "colab": {}
      },
      "source": [
        "# Lowercase all characters\n",
        "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
        "lines.deu=lines.ger.apply(lambda x: x.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9bLMfF59-KNX",
        "colab": {}
      },
      "source": [
        "# Remove quotes\n",
        "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
        "lines.deu=lines.ger.apply(lambda x: re.sub(\"'\", '', x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t-rYHNHd-KQK",
        "colab": {}
      },
      "source": [
        "exclude = set(string.punctuation) # Set of all special characters\n",
        "# Remove all the special characters\n",
        "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "lines.deu=lines.ger.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bWGhz8JG-KVi",
        "colab": {}
      },
      "source": [
        "# Remove all numbers from text\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
        "lines.deu=lines.ger.apply(lambda x: x.translate(remove_digits))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qCJnKqIY-KYm",
        "colab": {}
      },
      "source": [
        "# Remove extra spaces\n",
        "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
        "lines.deu=lines.ger.apply(lambda x: x.strip())\n",
        "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "lines.deu=lines.ger.apply(lambda x: re.sub(\" +\", \" \", x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5slsI5P7-Ja-",
        "outputId": "6af60a87-6f83-4754-d35a-05cf72d931ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "lines.sample(10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>ger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2882</th>\n",
              "      <td>more links to the capital will be available for example to the people in the ostrava region as the railways are adding one pendolino to that line</td>\n",
              "      <td>Mehrere Verbindungsmöglichkeiten in die Hauptstadt erhalten zum Beispiel die Bewohner des Ostrava-Gebiets, die Eisenbahn setzt für diese Strecke Züge des Typs Pendolino ein.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3198</th>\n",
              "      <td>the new us policy stresses that if the cuban government takes concrete steps such as freeing political prisoners and creating more space for opposition the united states will reciprocate</td>\n",
              "      <td>Die neue US-Politik legt Wert darauf, dass die Vereinigten Staaten eine Gegenleistung erbringen werden, wenn die kubanische Regierung konkrete Schritte in diese Richtung unternimmt, wie Freilassun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4006</th>\n",
              "      <td>around a hundred people also demonstrated in istanbul</td>\n",
              "      <td>Hunderte Menschen demonstrierten ebenfalls in Istanbul.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4423</th>\n",
              "      <td>whether these illusions are perceived to be pleasant or unpleasant is often only a matter of perspective</td>\n",
              "      <td>Ob Trugbilder als angenehm oder unangenehm empfunden werden, ist oft nur eine Frage des Standpunkts.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>if the mobile operators are looking the other way concerning this procedure</td>\n",
              "      <td>Verschließen die Mobilfunkanbieter vor einem solchen Vorgehen die Augen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>they travel at night</td>\n",
              "      <td>Nachts hin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>at the time</td>\n",
              "      <td>Zu diesem Zeitpunkt argumentierte das Ministerium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4982</th>\n",
              "      <td>they work with users in garages technicians and insurance companies</td>\n",
              "      <td>Sie arbeiten mit 24.000 Benutzern in Werkstätten, 3.100 Gutachtern und 53 Versicherungsgesellschaften zusammen.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3607</th>\n",
              "      <td>if you add up all the placement work proposed before the exam you already end up with more presence in front of students which equates to over hours he continued</td>\n",
              "      <td>Er sagte weiterhin : \"Wenn Sie alle vor der Leistungsprüfung angebotenen Praktika hinzufügen, erreichen Sie noch mehr Stunden, die Sie vor den Schülern verbracht haben, d.h. mehr als 300 Stunden.\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1700</th>\n",
              "      <td>there is a border along which there has been no agreement for too long a time and</td>\n",
              "      <td>Es gibt eine Grenzlinie</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                             eng                                                                                                                                                                                                      ger\n",
              "2882                                           more links to the capital will be available for example to the people in the ostrava region as the railways are adding one pendolino to that line                            Mehrere Verbindungsmöglichkeiten in die Hauptstadt erhalten zum Beispiel die Bewohner des Ostrava-Gebiets, die Eisenbahn setzt für diese Strecke Züge des Typs Pendolino ein.\n",
              "3198  the new us policy stresses that if the cuban government takes concrete steps such as freeing political prisoners and creating more space for opposition the united states will reciprocate  Die neue US-Politik legt Wert darauf, dass die Vereinigten Staaten eine Gegenleistung erbringen werden, wenn die kubanische Regierung konkrete Schritte in diese Richtung unternimmt, wie Freilassun...\n",
              "4006                                                                                                                                       around a hundred people also demonstrated in istanbul                                                                                                                                                  Hunderte Menschen demonstrierten ebenfalls in Istanbul.\n",
              "4423                                                                                    whether these illusions are perceived to be pleasant or unpleasant is often only a matter of perspective                                                                                                     Ob Trugbilder als angenehm oder unangenehm empfunden werden, ist oft nur eine Frage des Standpunkts.\n",
              "261                                                                                                                  if the mobile operators are looking the other way concerning this procedure                                                                                                                                  Verschließen die Mobilfunkanbieter vor einem solchen Vorgehen die Augen\n",
              "480                                                                                                                                                                         they travel at night                                                                                                                                                                                               Nachts hin\n",
              "886                                                                                                                                                                                  at the time                                                                                                                                                        Zu diesem Zeitpunkt argumentierte das Ministerium\n",
              "4982                                                                                                                         they work with users in garages technicians and insurance companies                                                                                          Sie arbeiten mit 24.000 Benutzern in Werkstätten, 3.100 Gutachtern und 53 Versicherungsgesellschaften zusammen.\n",
              "3607                           if you add up all the placement work proposed before the exam you already end up with more presence in front of students which equates to over hours he continued     Er sagte weiterhin : \"Wenn Sie alle vor der Leistungsprüfung angebotenen Praktika hinzufügen, erreichen Sie noch mehr Stunden, die Sie vor den Schülern verbracht haben, d.h. mehr als 300 Stunden.\"\n",
              "1700                                                                                                           there is a border along which there has been no agreement for too long a time and                                                                                                                                                                                  Es gibt eine Grenzlinie"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tum2mSmK-Jeq",
        "colab": {}
      },
      "source": [
        "# Vocabulary of English\n",
        "all_eng_words=set()\n",
        "for eng in lines.eng:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "# Vocabulary of German \n",
        "all_german_words=set()\n",
        "for ger in lines.ger:\n",
        "    for word in ger.split():\n",
        "        if word not in all_german_words:\n",
        "            all_german_words.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gGrnrWLw-Jhr",
        "outputId": "7115c036-79b0-418c-9313-d13e44d2b68a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Max Length of source sequence\n",
        "import numpy as np\n",
        "lenght_list=[]\n",
        "for l in lines.eng:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_src = np.max(lenght_list)\n",
        "max_length_src"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NKYTzcsw-Jls",
        "outputId": "c4ba6cef-5148-4c97-fa8d-0d22dcb90166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Max Length of target sequence\n",
        "lenght_list=[]\n",
        "for l in lines.ger:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_tar = np.max(lenght_list)\n",
        "max_length_tar"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xQirCJ8xIA8",
        "colab_type": "text"
      },
      "source": [
        "# Make a threshold here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLxosVx4wds5",
        "colab_type": "text"
      },
      "source": [
        "### 3a)- Defining input and target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z8TUTnn4AC9c",
        "outputId": "44f210f7-cf0d-41d9-8deb-5f1a922d1217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_german_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_german_words)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10955, 20535)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G06K661ZADAo",
        "outputId": "1befd2a6-454d-4fd4-97d4-b71d3986eff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_decoder_tokens += 1 # For zero padding\n",
        "num_decoder_tokens"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20536"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pw2TwZh6ADGE",
        "colab": {}
      },
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3_DwM1HCADJk",
        "colab": {}
      },
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SKleAlZwdtA",
        "colab_type": "text"
      },
      "source": [
        "### 3b)-Train - Test Split\n",
        "\n",
        "For validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kj_K6FfeAeYC",
        "outputId": "abdba721-08d5-4bfb-b0ef-1ae29bddc6d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X, y = lines.eng, lines.ger #X being input, y being target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4000,), (1000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LZYt7v-fCOQt"
      },
      "source": [
        "**Save the train and test dataframes for reproducing the results later, as they are shuffled**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GvpxI3i7A3BT",
        "colab": {}
      },
      "source": [
        "X_train.to_pickle('X_train.pkl')\n",
        "X_test.to_pickle('X_test.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f99GUE2iA3E5",
        "colab": {}
      },
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G_MQxfbrCj_E"
      },
      "source": [
        "# 4)-Encoder - Decoder Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WAKup9U3A3II",
        "colab": {}
      },
      "source": [
        "latent_dim = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NVWXpjPeA3K4",
        "outputId": "1bd4ba9f-e69e-4cf5-d8c1-5dc1f41fb5a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y5NPVx5SAebD",
        "colab": {}
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jmJpG9LHAegu",
        "outputId": "c28a6809-0f20-4879-fedd-a6288f7fc1d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZYb2KO_TAepD",
        "colab": {}
      },
      "source": [
        "#from IPython.display import Image\n",
        "#Image(retina=True, filename='train.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dEJCmevEAesV",
        "colab": {}
      },
      "source": [
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 128\n",
        "epochs = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bYQOjYpjEmfJ",
        "outputId": "51bdf96b-419d-4ec8-f469-4d03a338d521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 50)     547750      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 50)     1026800     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 50), (None,  20200       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 50), ( 20200       embedding_2[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 20536)  1047336     lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 2,662,286\n",
            "Trainable params: 2,662,286\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8_dLHRGWAemn",
        "outputId": "03c2212f-fbd8-4734-9b62-725c00ae3ddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        }
      },
      "source": [
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
        "                    validation_steps = val_samples//batch_size)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Epoch 1/15\n",
            "31/31 [==============================] - 35s 1s/step - loss: 9.2373 - acc: 0.0284 - val_loss: 8.4184 - val_acc: 0.0392\n",
            "Epoch 2/15\n",
            "31/31 [==============================] - 30s 969ms/step - loss: 8.0842 - acc: 0.0366 - val_loss: 8.2181 - val_acc: 0.0381\n",
            "Epoch 3/15\n",
            "31/31 [==============================] - 30s 966ms/step - loss: 7.9106 - acc: 0.0366 - val_loss: 8.3575 - val_acc: 0.0379\n",
            "Epoch 4/15\n",
            "31/31 [==============================] - 30s 969ms/step - loss: 7.8832 - acc: 0.0359 - val_loss: 8.5018 - val_acc: 0.0387\n",
            "Epoch 5/15\n",
            "31/31 [==============================] - 30s 960ms/step - loss: 7.8660 - acc: 0.0362 - val_loss: 8.6565 - val_acc: 0.0372\n",
            "Epoch 6/15\n",
            "31/31 [==============================] - 30s 963ms/step - loss: 7.8450 - acc: 0.0358 - val_loss: 8.7571 - val_acc: 0.0385\n",
            "Epoch 7/15\n",
            "31/31 [==============================] - 30s 959ms/step - loss: 7.8127 - acc: 0.0363 - val_loss: 8.8164 - val_acc: 0.0373\n",
            "Epoch 8/15\n",
            "31/31 [==============================] - 30s 954ms/step - loss: 7.7781 - acc: 0.0368 - val_loss: 8.8293 - val_acc: 0.0408\n",
            "Epoch 9/15\n",
            "31/31 [==============================] - 30s 961ms/step - loss: 7.7282 - acc: 0.0382 - val_loss: 8.7908 - val_acc: 0.0403\n",
            "Epoch 10/15\n",
            "31/31 [==============================] - 30s 961ms/step - loss: 7.6795 - acc: 0.0392 - val_loss: 8.7403 - val_acc: 0.0344\n",
            "Epoch 11/15\n",
            "31/31 [==============================] - 30s 962ms/step - loss: 7.6381 - acc: 0.0372 - val_loss: 8.7508 - val_acc: 0.0361\n",
            "Epoch 12/15\n",
            "31/31 [==============================] - 30s 955ms/step - loss: 7.6026 - acc: 0.0371 - val_loss: 8.7227 - val_acc: 0.0415\n",
            "Epoch 13/15\n",
            "31/31 [==============================] - 30s 959ms/step - loss: 7.5654 - acc: 0.0379 - val_loss: 8.7493 - val_acc: 0.0395\n",
            "Epoch 14/15\n",
            "31/31 [==============================] - 30s 959ms/step - loss: 7.5320 - acc: 0.0377 - val_loss: 8.7450 - val_acc: 0.0406\n",
            "Epoch 15/15\n",
            "31/31 [==============================] - 30s 962ms/step - loss: 7.4995 - acc: 0.0376 - val_loss: 8.7470 - val_acc: 0.0409\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4a18653e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S5p1pg6XAekB",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "model.save_weights('translate.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bg0C_Xo0Aedy",
        "colab": {}
      },
      "source": [
        "model.load_weights('translate.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5MuBJTzQNTVn"
      },
      "source": [
        "# Inference Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DYLNM2LFNMAp",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yp5DWmhDNaSX"
      },
      "source": [
        "# Decode sample sequeces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qZnHAo2KNX1R",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \"\"\"\n",
        "    \n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BmOR00fXNgFe"
      },
      "source": [
        "# Evaluation on Train Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vm_zRElrNd39",
        "colab": {}
      },
      "source": [
        "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gUFD9t9ENhbG",
        "outputId": "26fc74a9-1dba-47ad-f8fc-5b0b30081be6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual German Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted German Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: the hang seng index of the hong kong stock exchange wrote off nearly four percent during the day\n",
            "Actual German Translation: dex der Hang Seng Börse in Hongkong verlor im Laufe des Geschäftstages fast vier Prozentpu\n",
            "Predicted German Translation:  der ist der ist der der ist der der der der der\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x5j_RvtnNheP",
        "outputId": "294afba4-db4b-450f-adef-388a0c28210b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual German Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted German Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: the mayor of gioia tauro was disposed towards conforming municipal interests with those of the piromalli gang\n",
            "Actual German Translation: ürgermeister von Gioia Tauro war be\n",
            "Predicted German Translation:  der ist der ist der der ist der der der der der\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t7KzAzWTNhhh",
        "outputId": "58af442f-bd0b-40bb-cbb0-b8c330abbc6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual German Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted German Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: i shot the photo of this post during the microsoft employees break\n",
            "Actual German Translation: to von diesem Ort habe ich in Red\n",
            "Predicted German Translation:  der ist der der ist der der der ist der der der\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2tpV8t7HOc8R"
      },
      "source": [
        "# Evaluation on Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ew_6eBkXNhkm",
        "colab": {}
      },
      "source": [
        "val_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JAc4u_sbOgV8",
        "outputId": "aefe99ea-7315-4bf8-f92f-2c34e11f8e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(val_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_test[k:k+1].values[0])\n",
        "print('Actual German Translation:', y_test[k:k+1].values[0][6:-4])\n",
        "print('Predicted German Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: we have made great progress towards an agreement that will be effective on the market\n",
            "Actual German Translation: aben große Fortschritte in Richtung einer Einigung gem\n",
            "Predicted German Translation:  der ist der der ist der der der ist der der der\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6qjx9jmtOlBn",
        "outputId": "afab46d2-62ae-48c9-c2cc-760d20597b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(val_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_test[k:k+1].values[0])\n",
        "print('Actual German Translation:', y_test[k:k+1].values[0][6:-4])\n",
        "print('Predicted German Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: however\n",
            "Actual German Translation: mt jedoch darau\n",
            "Predicted German Translation:  der der ist der der der der der der der der der\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mt_UxJJhOt8l",
        "outputId": "4d31f625-a740-4935-af10-f5c357c53234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(val_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_test[k:k+1].values[0])\n",
        "print('Actual German Translation:', y_test[k:k+1].values[0][6:-4])\n",
        "print('Predicted German Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: the appointment of a special prosecutor with the power to force witnesses to testify was one of his key recommendations\n",
            "Actual German Translation: rufung eines Spezialermittlers mit der Befu\n",
            "Predicted German Translation:  der ist der der ist der der der ist der der der\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y9ZlXDsjOxMO",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}