{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Simple_Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HassanSherwani/Language_Translator/blob/master/Simple_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QJxJLfT6m4zo"
      },
      "source": [
        "# Machine Translation\n",
        "\n",
        "English-German Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YvFSu3KOnCQI"
      },
      "source": [
        "# 1)- Importing key modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ydSdCo4JzRta",
        "colab": {}
      },
      "source": [
        "#support both Python 2 and Python 3 with minimal overhead.\n",
        "from __future__ import absolute_import, division, print_function\n",
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HXdjBXc-zNXe",
        "colab": {}
      },
      "source": [
        "import string \n",
        "import re \n",
        "from numpy import array, argmax, random, take \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline \n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ElRcz5K3hJrC",
        "outputId": "a69be058-c84c-4b6d-dc64-863b2b1dd1c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model \n",
        "from keras import optimizers \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XN_b91atnHye"
      },
      "source": [
        "# 2)- Reading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ffc2bMb7xJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to read raw text file\n",
        "def read_text(filename): \n",
        "        # open the file \n",
        "        file = open(filename, mode='rt', encoding='utf-8') \n",
        "        \n",
        "        # read all text \n",
        "        text = file.read() \n",
        "        file.close() \n",
        "        return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6ucxbaz7xMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split text into sentences \n",
        "def to_lines(text): \n",
        "      sents = text.strip().split('\\n') \n",
        "      sents = [i.split('\\t') for i in sents] \n",
        "      return sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P23QEeky7xPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = read_text(\"random_data.txt\") \n",
        "deu_eng = to_lines(data) \n",
        "deu_eng = array(deu_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uE4Ka5gVYq-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9951b18a-9a76-4a01-c786-7da1582cab2d"
      },
      "source": [
        "type(deu_eng)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sQ0sxkw7xS3",
        "colab_type": "code",
        "outputId": "4d83a143-d5da-459f-d0b3-03edd52168e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "# for english part \n",
        "deu_eng[:,0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['india and japan prime ministers meet in tokyo',\n",
              "       'indias new prime minister narendra modi is meeting his japanese counterpart shinzo abe in tokyo to discuss economic and security ties on his first major foreign visit since winning mays election',\n",
              "       'mr modi is on a fiveday trip to japan to strengthen economic ties with the third largest economy in the world',\n",
              "       ..., 'five minutes later the first mountainbikers set off',\n",
              "       'bent hansen chairman of the association cycling on the grosser feldberg gave the starting orders and wished those taking part an enjoyable trip',\n",
              "       'next year he hopes to have safety barriers on the course for the benefit of those taking part on the feldberg'],\n",
              "      dtype='<U511')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMxTVt657xV9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "f09ae73a-9421-4b65-f565-f74e33ccec9f"
      },
      "source": [
        "# for german version of data\n",
        "deu_eng[:,1]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['die premierminister indiens und japans trafen sich in tokio',\n",
              "       'indiens neuer premierminister narendra modi trifft bei seinem ersten wichtigen auslandsbesuch seit seinem wahlsieg im mai seinen japanischen amtskollegen shinzo abe in toko um wirtschaftliche und sicherheitspolitische beziehungen zu besprechen',\n",
              "       'herr modi befindet sich auf einer funftagigen reise nach japan um die wirtschaftlichen beziehungen mit der drittgroten wirtschaftsnation der welt zu festigen',\n",
              "       ..., 'funf minuten spater legten die ersten mountainbiker los',\n",
              "       'bent hansen vorsitzender des vereins radeln auf den groen feldberg gab die startkommandos und wunschte den teilnehmern einen schonen ausflug',\n",
              "       'fur nachstes jahr hoffe er dass es gelingt die strecke zum feldberg hinauf zur sicherheit der teilnehmer zu sperren'],\n",
              "      dtype='<U511')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUZ6BSmvtJ1s",
        "colab_type": "text"
      },
      "source": [
        "# 3)-Text Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GEia-m7ViPLD"
      },
      "source": [
        "### 3.1)-Text cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WmC81k-wh8ZJ",
        "colab": {}
      },
      "source": [
        "# Remove punctuation \n",
        "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]] \n",
        "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]] \n",
        "\n",
        "# convert text to lowercase \n",
        "for i in range(len(deu_eng)): \n",
        "    deu_eng[i,0] = deu_eng[i,0].lower() \n",
        "    deu_eng[i,1] = deu_eng[i,1].lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4FdyDdXwiS9i"
      },
      "source": [
        "### 3.2)-Text to Sequence Conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8pxu1-xNh8cA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "82c20837-8df2-4ad5-8a48-2a264cf155fc"
      },
      "source": [
        "# empty lists \n",
        "eng_l = [] \n",
        "deu_l = [] \n",
        "\n",
        "# populate the lists with sentence lengths \n",
        "for i in deu_eng[:,0]: \n",
        "      eng_l.append(len(i.split())) \n",
        "\n",
        "for i in deu_eng[:,1]: \n",
        "      deu_l.append(len(i.split())) \n",
        "\n",
        "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
        "length_df.hist(bins = 30) \n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2De4ZERJzX_4"
      },
      "source": [
        "the maximum length of the German sentences is of max. range of 68 and that of the English phrases is 68. But, their graph pattern is different from each other"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lpt6tCjfkGKu"
      },
      "source": [
        "### 3.3)-vectorize our text data \n",
        "\n",
        "by using Kerasâ€™s Tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_j_y_uZ7h8e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d17d7f4-83b0-4cfc-9c38-fbf913884cb4"
      },
      "source": [
        "# function to build a tokenizer \n",
        "def tokenization(lines): \n",
        "      tokenizer = Tokenizer() \n",
        "      tokenizer.fit_on_texts(lines) \n",
        "      return tokenizer\n",
        "\n",
        "# prepare english tokenizer \n",
        "eng_tokenizer = tokenization(deu_eng[:, 0]) \n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1 \n",
        "eng_length = 8 \n",
        "\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 7231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0ha_ZNySh8hh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fded5c70-e999-42d2-f386-9973e78d1888"
      },
      "source": [
        "# prepare Deutch tokenizer \n",
        "deu_tokenizer = tokenization(deu_eng[:, 1]) \n",
        "deu_vocab_size = len(deu_tokenizer.word_index) + 1 \n",
        "deu_length = 8 \n",
        "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deutch Vocabulary Size: 9284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XvmowmplzfdT"
      },
      "source": [
        "There is difference in amount of words in two languages.We need to encode sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cUY-Py6WzhtB"
      },
      "source": [
        "### 3.4)-encode and pad sequences "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QElAizsykOtJ",
        "colab": {}
      },
      "source": [
        "def encode_sequences(tokenizer, length, lines):          \n",
        "         # integer encode sequences          \n",
        "         seq = tokenizer.texts_to_sequences(lines)          \n",
        "         # pad sequences with 0 values          \n",
        "         seq = pad_sequences(seq, maxlen=length, padding='post')           \n",
        "         return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "408A3w7Ukb4r"
      },
      "source": [
        "# 4)-Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kJF5iWUOnUgC"
      },
      "source": [
        "### 4.1)- Train-test Split\n",
        "\n",
        "80%-20%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GzxozTM0kZk7",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# split data into train and test set \n",
        "train,test= train_test_split(deu_eng,test_size=0.2,random_state= 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xvyO7SdQkr88"
      },
      "source": [
        "### 4.2)- Defining input and target\n",
        "We will encode English sentences as the input sequences and German sentences as the target sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wJvJMU9Vzr-7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "fcef5eaa-7927-46fb-b7a5-6d6cee875b87"
      },
      "source": [
        "# english version\n",
        "train[:, 0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['its not my responsibility',\n",
              "       'meanwhile in our homes items as innocuous as floor tiles or shed roofs have routinely contained asbestos',\n",
              "       'she said i keep thinking this world did not get better within these years',\n",
              "       ...,\n",
              "       'crops are rotting in the fields mines have been deserted and the markets have been abandoned the virus has cost the region dearly',\n",
              "       'the preparations for the party are well underway in tannenwald gun club which will celebrate years since being established on to september',\n",
              "       'it also means higher taxes'], dtype='<U511')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TcMT6wFoztLT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "c62222b0-6c73-4d70-a762-1892fca4c21b"
      },
      "source": [
        "# english version\n",
        "train[:, 1]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ich bin nicht dafur verantwortlich',\n",
              "       'und derweil haben so unschuldige gegenstande in unseren hausern wie fubodenplatten oder schuppendacher standardmaig asbest enthalten',\n",
              "       'sie sagte ich denke immer dass diese welt in diesen jahren nicht besser geworden ist',\n",
              "       ...,\n",
              "       'die ernte verrottet auf den feldern die minen sind verlassen und die markte verwaist das virus hat der region schwer zugesetzt',\n",
              "       'auf hochtouren laufen beim schutzenverein tannenwald die vorbereitungen fur das grundungsfest von bis september',\n",
              "       'sie bedeutet auch hohere steuern'], dtype='<U511')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P6ZhWiJdkkb8",
        "colab": {}
      },
      "source": [
        "# prepare training data \n",
        "trainX = encode_sequences(eng_tokenizer, deu_length, train[:, 0]) \n",
        "trainY = encode_sequences(deu_tokenizer, eng_length, train[:, 1]) \n",
        "\n",
        "# prepare validation data \n",
        "testX = encode_sequences(eng_tokenizer, deu_length, test[:, 0]) \n",
        "testY = encode_sequences(deu_tokenizer, eng_length, test[:, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f2LKJrFfz0GI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "b86d6ffd-6d26-44b9-c700-c04eef86fd7f"
      },
      "source": [
        "print(trainX[:5])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  48   23   51 4075    0    0    0    0]\n",
            " [2904   64 2016 5284   17 5285 2943   65]\n",
            " [ 141   97   23   98  179  362  193   58]\n",
            " [  69  610  427   23 1523 1892 2202 5445]\n",
            " [1329    3  113   76    1  204 3174    4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L81CkA-Rz0Jh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "344d4800-35e5-4c3f-9156-b972f7b8dcca"
      },
      "source": [
        "print(trainY[:5])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  15  184   18  272 1521    0    0    0]\n",
            " [1071   30 2751   59 6215 6216   85 1223]\n",
            " [ 197    4  261  100   18  323  708   16]\n",
            " [6478   55 1233  208 6479 6480  956 1466]\n",
            " [ 264    5  550    6    4  592    6  180]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "plUoF_-gz0Mh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "b0de407b-6f83-497a-958b-b06821acda0a"
      },
      "source": [
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "print(testX.shape)\n",
        "print(testY.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5205, 8)\n",
            "(5205, 8)\n",
            "(1302, 8)\n",
            "(1302, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ubte9AUngfx"
      },
      "source": [
        "### 4.3)- build NMT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CuEMUhwV248X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "732020e0-4dbe-4ce1-daae-6669b447ad1b"
      },
      "source": [
        "eng_length"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "afiv_7mw26av",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cec834e-007b-41ee-c079-0034c28d4dc0"
      },
      "source": [
        "deu_length"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yORpCfMCkkjz",
        "colab": {}
      },
      "source": [
        " def build_model(in_vocab,out_vocab, in_timesteps,out_timesteps,n):   \n",
        "      model = Sequential() \n",
        "      model.add(Embedding(in_vocab, n, input_length=in_timesteps,   \n",
        "      mask_zero=True)) \n",
        "      model.add(LSTM(n)) \n",
        "      model.add(RepeatVector(out_timesteps)) \n",
        "      model.add(LSTM(n, return_sequences=True))  \n",
        "      model.add(Dense(out_vocab, activation='softmax')) \n",
        "      return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H_0LMdC6lgnp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "8e9a6e4e-20d9-4d72-978f-dd47b46967b0"
      },
      "source": [
        "# model compilation (with 512 hidden units)\n",
        "model = build_model(eng_vocab_size,deu_vocab_size, eng_length, deu_length, 512)\n",
        "\n",
        "rms = optimizers.RMSprop(lr=0.001) \n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BA8KW2_80Hs3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "0e4215b7-66a7-4442-c2c5-3cbe0a6aaf1f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 8, 512)            3702272   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 512)               2099200   \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 8, 512)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 8, 512)            2099200   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8, 9284)           4762692   \n",
            "=================================================================\n",
            "Total params: 12,663,364\n",
            "Trainable params: 12,663,364\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9M1ukVFAlkFz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b549176c-47c1-4573-b53f-3da7dd8f5697"
      },
      "source": [
        "filename = 'model_translate.h1' \n",
        "\n",
        "# set checkpoint\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss',  \n",
        "                             verbose=1, save_best_only=True, \n",
        "                             mode='min') \n",
        "\n",
        "\n",
        "# train model \n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
        "                    epochs=30, batch_size=512, validation_split = 0.2, \n",
        "                    callbacks=[checkpoint], verbose=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Train on 4164 samples, validate on 1041 samples\n",
            "Epoch 1/30\n",
            "4164/4164 [==============================] - 8s 2ms/step - loss: 8.2239 - val_loss: 7.3432\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 7.34316, saving model to model_translate.h1\n",
            "Epoch 2/30\n",
            "4164/4164 [==============================] - 2s 546us/step - loss: 7.0973 - val_loss: 7.2177\n",
            "\n",
            "Epoch 00002: val_loss improved from 7.34316 to 7.21767, saving model to model_translate.h1\n",
            "Epoch 3/30\n",
            "4164/4164 [==============================] - 2s 548us/step - loss: 6.9842 - val_loss: 7.1847\n",
            "\n",
            "Epoch 00003: val_loss improved from 7.21767 to 7.18468, saving model to model_translate.h1\n",
            "Epoch 4/30\n",
            "4164/4164 [==============================] - 2s 548us/step - loss: 6.9288 - val_loss: 7.1315\n",
            "\n",
            "Epoch 00004: val_loss improved from 7.18468 to 7.13151, saving model to model_translate.h1\n",
            "Epoch 5/30\n",
            "4164/4164 [==============================] - 2s 548us/step - loss: 6.8462 - val_loss: 7.1350\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 7.13151\n",
            "Epoch 6/30\n",
            "4164/4164 [==============================] - 2s 543us/step - loss: 6.8135 - val_loss: 7.0500\n",
            "\n",
            "Epoch 00006: val_loss improved from 7.13151 to 7.05001, saving model to model_translate.h1\n",
            "Epoch 7/30\n",
            "4164/4164 [==============================] - 2s 550us/step - loss: 6.7550 - val_loss: 7.0180\n",
            "\n",
            "Epoch 00007: val_loss improved from 7.05001 to 7.01803, saving model to model_translate.h1\n",
            "Epoch 8/30\n",
            "4164/4164 [==============================] - 2s 550us/step - loss: 6.7456 - val_loss: 7.0033\n",
            "\n",
            "Epoch 00008: val_loss improved from 7.01803 to 7.00334, saving model to model_translate.h1\n",
            "Epoch 9/30\n",
            "4164/4164 [==============================] - 2s 554us/step - loss: 6.6569 - val_loss: 6.9297\n",
            "\n",
            "Epoch 00009: val_loss improved from 7.00334 to 6.92969, saving model to model_translate.h1\n",
            "Epoch 10/30\n",
            "4164/4164 [==============================] - 2s 553us/step - loss: 6.6243 - val_loss: 6.9162\n",
            "\n",
            "Epoch 00010: val_loss improved from 6.92969 to 6.91618, saving model to model_translate.h1\n",
            "Epoch 11/30\n",
            "4164/4164 [==============================] - 2s 547us/step - loss: 6.5719 - val_loss: 6.8671\n",
            "\n",
            "Epoch 00011: val_loss improved from 6.91618 to 6.86705, saving model to model_translate.h1\n",
            "Epoch 12/30\n",
            "4164/4164 [==============================] - 2s 552us/step - loss: 6.4945 - val_loss: 6.9912\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 6.86705\n",
            "Epoch 13/30\n",
            "4164/4164 [==============================] - 2s 549us/step - loss: 6.5019 - val_loss: 6.8510\n",
            "\n",
            "Epoch 00013: val_loss improved from 6.86705 to 6.85097, saving model to model_translate.h1\n",
            "Epoch 14/30\n",
            "4164/4164 [==============================] - 2s 548us/step - loss: 6.4065 - val_loss: 6.8989\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 6.85097\n",
            "Epoch 15/30\n",
            "4164/4164 [==============================] - 2s 550us/step - loss: 6.3757 - val_loss: 6.7143\n",
            "\n",
            "Epoch 00015: val_loss improved from 6.85097 to 6.71427, saving model to model_translate.h1\n",
            "Epoch 16/30\n",
            "4164/4164 [==============================] - 2s 558us/step - loss: 6.3082 - val_loss: 6.8321\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 6.71427\n",
            "Epoch 17/30\n",
            "4164/4164 [==============================] - 2s 553us/step - loss: 6.2863 - val_loss: 6.6391\n",
            "\n",
            "Epoch 00017: val_loss improved from 6.71427 to 6.63913, saving model to model_translate.h1\n",
            "Epoch 18/30\n",
            "4164/4164 [==============================] - 2s 554us/step - loss: 6.2261 - val_loss: 6.6123\n",
            "\n",
            "Epoch 00018: val_loss improved from 6.63913 to 6.61225, saving model to model_translate.h1\n",
            "Epoch 19/30\n",
            "4164/4164 [==============================] - 2s 556us/step - loss: 6.1568 - val_loss: 6.5551\n",
            "\n",
            "Epoch 00019: val_loss improved from 6.61225 to 6.55513, saving model to model_translate.h1\n",
            "Epoch 20/30\n",
            "4164/4164 [==============================] - 2s 546us/step - loss: 6.0896 - val_loss: 6.6636\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 6.55513\n",
            "Epoch 21/30\n",
            "4164/4164 [==============================] - 2s 553us/step - loss: 6.1031 - val_loss: 6.4823\n",
            "\n",
            "Epoch 00021: val_loss improved from 6.55513 to 6.48228, saving model to model_translate.h1\n",
            "Epoch 22/30\n",
            "4164/4164 [==============================] - 2s 559us/step - loss: 6.0479 - val_loss: 6.5282\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 6.48228\n",
            "Epoch 23/30\n",
            "4164/4164 [==============================] - 2s 553us/step - loss: 5.9817 - val_loss: 6.4618\n",
            "\n",
            "Epoch 00023: val_loss improved from 6.48228 to 6.46183, saving model to model_translate.h1\n",
            "Epoch 24/30\n",
            "4164/4164 [==============================] - 2s 549us/step - loss: 5.9341 - val_loss: 6.3973\n",
            "\n",
            "Epoch 00024: val_loss improved from 6.46183 to 6.39731, saving model to model_translate.h1\n",
            "Epoch 25/30\n",
            "4164/4164 [==============================] - 2s 557us/step - loss: 5.8861 - val_loss: 6.5144\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 6.39731\n",
            "Epoch 26/30\n",
            "4164/4164 [==============================] - 2s 556us/step - loss: 5.8600 - val_loss: 6.3490\n",
            "\n",
            "Epoch 00026: val_loss improved from 6.39731 to 6.34903, saving model to model_translate.h1\n",
            "Epoch 27/30\n",
            "4164/4164 [==============================] - 2s 553us/step - loss: 5.7943 - val_loss: 6.3782\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 6.34903\n",
            "Epoch 28/30\n",
            "4164/4164 [==============================] - 2s 555us/step - loss: 5.7407 - val_loss: 6.2749\n",
            "\n",
            "Epoch 00028: val_loss improved from 6.34903 to 6.27492, saving model to model_translate.h1\n",
            "Epoch 29/30\n",
            "4164/4164 [==============================] - 2s 553us/step - loss: 5.7072 - val_loss: 6.2684\n",
            "\n",
            "Epoch 00029: val_loss improved from 6.27492 to 6.26838, saving model to model_translate.h1\n",
            "Epoch 30/30\n",
            "4164/4164 [==============================] - 2s 558us/step - loss: 5.6358 - val_loss: 6.2016\n",
            "\n",
            "Epoch 00030: val_loss improved from 6.26838 to 6.20161, saving model to model_translate.h1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nwrL0_sjmUuO"
      },
      "source": [
        "# 5)-Plotting results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iUYdtjQXlupF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "8b2dcc9d-07ca-4720-f43b-8e1e5368c69e"
      },
      "source": [
        "plt.plot(history.history['loss']) \n",
        "plt.plot(history.history['val_loss']) \n",
        "plt.legend(['train','validation']) \n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VGW+x/HPk947IY2QUIRAqAlF\nFKSpFEVQim1XUBd1rXfXe5f13l3Lde91d11X91oQQRcLIKIIstgF6SUgJfSSHkIa6XUyz/3jDBBi\nEtInM/m9X695ZeacM2eew7z45uQ5z/k9SmuNEEII++Jg7QYIIYRoexLuQghhhyTchRDCDkm4CyGE\nHZJwF0IIOyThLoQQdkjCXQgh7JCEuxBC2CEJdyGEsENO1vrgoKAgHRUVZa2PF0IIm7Rv375crXW3\nq21ntXCPiooiISHBWh8vhBA2SSmV0pTtpFtGCCHskIS7EELYIQl3IYSwQ1brcxdC2Jfq6mrS09Op\nqKiwdlPsgpubGxERETg7O7fo/RLuQog2kZ6ejre3N1FRUSilrN0cm6a1Ji8vj/T0dKKjo1u0D+mW\nEUK0iYqKCgIDAyXY24BSisDAwFb9FSThLoRoMxLsbae1/5Y2F+7Hs4r4y1fHKSyvtnZThBCi07K5\ncE/NK+PNzWdIySu1dlOEEJ1IQUEBb775ZrPfN23aNAoKCtqhRdZlc+Ee7u8OQMaFciu3RAjRmTQU\n7iaTqdH3bdy4ET8/v/ZqltXY3GiZCD8PADIKJNyFEJctWrSIM2fOMHToUJydnXFzc8Pf35/jx49z\n8uRJZs6cSVpaGhUVFTz55JMsXLgQuFwKpaSkhKlTp3L99dezY8cOwsPDWbduHe7u7lY+spaxuXD3\ncXfCy9WJdDlzF6LTev6LIxzNLGrTfQ4I8+HZWwc2uP6ll14iMTGRAwcOsHnzZqZPn05iYuKloYTv\nvvsuAQEBlJeXM2LECO644w4CAwOv2MepU6dYuXIl77zzDnPnzuXTTz/l3nvvbdPj6Cg2F+5KKcL9\n3CXchRCNGjly5BVjxP/xj3+wdu1aANLS0jh16tTPwj06OpqhQ4cCEBcXR3Jycoe1t63ZXLgDRPi7\nS7eMEJ1YY2fYHcXT0/PS882bN/Pdd9+xc+dOPDw8GD9+fL1jyF1dXS89d3R0pLzcdnPG5i6ognFR\nNeNCmbWbIYToRLy9vSkuLq53XWFhIf7+/nh4eHD8+HF27drVwa3reDZ55h7u505RhYmiimp83FpW\nd0EIYV8CAwO57rrriI2Nxd3dne7du19aN2XKFBYvXkxMTAz9+vVj9OjRVmxpx7DNcK81HNInVMJd\nCGFYsWJFvctdXV358ssv6113sV89KCiIxMTES8uffvrpNm9fR7LJbpkIf8twSLmoKoQQ9bLJcA/3\ns5y5y0VVIYSol02Ge5CXC65ODhLuQgjRAJsM98tj3WXEjBBC1Mcmwx0uDoeUM3chhKhPk8JdKfVv\nSqkjSqlEpdRKpZRbnfWuSqmPlVKnlVK7lVJR7dHY2uRGJiGEaNhVw10pFQ48AcRrrWMBR+DOOps9\nAFzQWvcB/g78ua0bWle4nzu5JVVUVNe090cJIeyQl5cXAJmZmcyePbvebcaPH09CQkKj+3n11Vcp\nK7vcRdxZSgg3tVvGCXBXSjkBHkBmnfW3Acstz9cAk1Q7T8lycay71JgRQrRGWFgYa9asafH764Z7\nZykhfNVw11pnAC8DqcA5oFBr/U2dzcKBNMv2JqAQCKyzDUqphUqpBKVUQk5OTqsaHi6lf4UQtSxa\ntIg33njj0uvnnnuOF198kUmTJjF8+HAGDRrEunXrfva+5ORkYmNjASgvL+fOO+8kJiaGWbNmXVFb\n5pFHHiE+Pp6BAwfy7LPPAkYxsszMTCZMmMCECRMAo4Rwbm4uAK+88gqxsbHExsby6quvXvq8mJgY\nfvWrXzFw4EBuuummdqlhc9U7VJVS/hhn5tFAAfCJUuperfWHzf0wrfUSYAlAfHy8bu77a4uQSTuE\n6Ly+XARZh9t2nyGDYOpLDa6eN28eTz31FI8++igAq1ev5uuvv+aJJ57Ax8eH3NxcRo8ezYwZMxqc\nn/Stt97Cw8ODY8eOcejQIYYPH35p3Z/+9CcCAgKoqalh0qRJHDp0iCeeeIJXXnmFTZs2ERQUdMW+\n9u3bx3vvvcfu3bvRWjNq1ChuuOEG/P39O6S0cFO6ZSYDSVrrHK11NfAZMKbONhlADwBL140vkNeW\nDa2ru48bTg6KjAIZDimEgGHDhpGdnU1mZiYHDx7E39+fkJAQnnnmGQYPHszkyZPJyMjg/PnzDe5j\ny5Ytl0J28ODBDB48+NK61atXM3z4cIYNG8aRI0c4evRoo+3Ztm0bs2bNwtPTEy8vL26//Xa2bt0K\ndExp4abUlkkFRiulPIByYBJQ9wrDeuA+YCcwG/hBa92qM/OrcXRQhPi6SZ+7EJ1RI2fY7WnOnDms\nWbOGrKws5s2bx0cffUROTg779u3D2dmZqKioekv9Xk1SUhIvv/wye/fuxd/fn/nz57doPxd1RGnh\npvS578a4SLofOGx5zxKl1AtKqRmWzZYBgUqp08BvgEVt3tJ6hPvJWHchxGXz5s1j1apVrFmzhjlz\n5lBYWEhwcDDOzs5s2rSJlJSURt8/bty4S8XHEhMTOXToEABFRUV4enri6+vL+fPnryhC1lCp4bFj\nx/L5559TVlZGaWkpa9euZezYsW14tI1rUlVIrfWzwLN1Fv+x1voKYE4btqtJwv3d2XmmXXt/hBA2\nZODAgRQXFxMeHk5oaCj33HMPt956K4MGDSI+Pp7+/fs3+v5HHnmEBQsWEBMTQ0xMDHFxcQAMGTKE\nYcOG0b9/f3r06MF111136T0LFy5kypQphIWFsWnTpkvLhw8fzvz58xk5ciQADz74IMOGDeuw2Z1U\nO/eeNCg+Pl5fbfzo1bzy7Ule/+EUJ16cirOjzd5sK4RdOHbsGDExMdZuhl2p799UKbVPax1/tffa\ndCJG+Llj1pBV2PK+LyGEsEc2He4Xb2RKkwJiQghxBdsOdz8Z6y5EZ2Ktbl571Np/S5sO91A/N5SS\nu1SF6Azc3NzIy8uTgG8DWmvy8vJwc3O7+sYNsMk5VC9ydXIk2NtVztyF6AQiIiJIT0+ntaVFhMHN\nzY2IiIgWv9+mwx2wTNoh4S6EtTk7OxMdHW3tZggLm+6WAQj395BuGSGEqMPmwz3C351zheWYzdLP\nJ4QQF9l8uIf7uVNdo8kurrR2U4QQotOw/XC/WPpXqkMKIcQlNh/uEX4yI5MQQtRl8+Eu0+0JIcTP\n2Xy4e7g4EeDpIiNmhBCiFpsPd5C67kIIUZfdhHu6FA8TQohL7CPc/d3JKCiXmhZCCGFhF+Ee4e9O\nRbWZ/NIqazdFCCE6BbsI90ulf+WiqhBCAPYS7jIcUgghrmAX4R7h5wHIpB1CCHGRXYS7j7sTXq5O\n0i0jhBAWdhHuSiki/KWuuxBCXGQX4Q6WG5nkzF0IIQB7Cnd/uZFJCCEusp9w93OnuMJEUUW1tZsi\nhBBWZzfhHuEvI2aEEOIiuwn3S5N2SLgLIYQdhfulSTuk310IIa4a7kqpfkqpA7UeRUqpp+psM14p\nVVhrmz+2X5PrF+TlgquTg4yYEUIIwOlqG2itTwBDAZRSjkAGsLaeTbdqrW9p2+Y1nVJKhkMKIYRF\nc7tlJgFntNYp7dGY1gr3l0k7hBACmh/udwIrG1h3rVLqoFLqS6XUwFa2q0XkLlUhhDA0OdyVUi7A\nDOCTelbvB3pqrYcA/wd83sA+FiqlEpRSCTk5OS1pb6PC/dzJK62ivKqmzfcthBC2pDln7lOB/Vrr\n83VXaK2LtNYllucbAWelVFA92y3RWsdrreO7devW4kY35NJwSOl3F0J0cc0J97tooEtGKRWilFKW\n5yMt+81rffOa59KNTBLuQogu7qqjZQCUUp7AjcBDtZY9DKC1XgzMBh5RSpmAcuBObYUJTS/NyCT9\n7kKILq5J4a61LgUC6yxbXOv568Drbdu05uvu44aTg5IbmYQQXZ7d3KEK4OigCPF1k24ZIUSXZ1fh\nDpa67tItI4To4uwu3CP8PeTMXQjR5dlduIf7u5NVVEGVyWztpgghhNXYXbhH+LmjNWQVVli7KUII\nYTW2F+7mGjjxVYOrL97IlF4gI2aEEF2X7YX7Tx/Aynnw/QtQz1D6CJm0QwghmjbOvVMZ9gvI2A9b\n/walOTD97+B4+TBCfd1RCikgJoTo0mwv3B0c4dbXwCsYtvwVyvLhjmXg7AaAi5MDwd6uMmJGCNGl\n2V63DIBSMPG/YMqf4fgG+PAOqCi8tFrGugshujrbDPeLRj8Mty+FtF3w3nQoNgpWylh3IURXZ9vh\nDjB4Dtz1MeSfgXdvgvyzhPu7c66wnBpzh9cuE0KITsH2wx2g72S47wuja2bZzcQ6pFBdo8kulrHu\nQoiuyT7CHSAiHu7/GhyduXnv/YxSx6TfXQjRZdlPuAN06wcPfIPZM4T3XV7CfPQLa7dICCGswr7C\nHcA3AtP8LzmqexK/5yn48nfGHa3lF6zdMiGE6DC2N869CTz8gnnU6TkWe7/L4L3LYPdiQEH3gRB5\nLfQcYzy8Q6zdVCGEaBd2Ge4Agf7+vOz5e95/bAVk7IOUHcbjwArY+46xUUAviLQEfdR14B9l1TYL\nIURbsdtwD/dz51R2MTi7Q9T1xgOgphqyDlnCfiec+Bcc+NBY12OUUd5g4Cxw9bJe44UQopXsNtwj\n/N3ZfDIbrTVKqcsrHJ0hPM54jHkczGbIPQGnvoH9H8D6x+CrRUbAD/8lRIww7ogVQggbYrfhHu7v\nTkW1mbzSKoK8XBve0MEBgmOMx5gnIG23EfKJnxkVKIP6wfBfwOA7watbxx2AEEK0gv2Gu9/l0r+N\nhnttSkHkaOMx9aXLAf/Nf8F3z0G/qTDslxA6BGqqLj9MlUZ3T02l5bVlubMH9J5gFDsTQogOZL/h\nfrGue0E5Q3r4NX8Hrt4Qd5/xyD5uhPzBlXCsmWPnw+Pglr8bvxCEEKKD2G24R/h5AG00aUdwf7j5\nTzDpWTj9LRSfA0dXcHQBJxfjp6Or0Z/vZPnp6ApZh+HbP8CS8TDqYZjwjPFLQwgh2pndhruPuxPe\nrk6kXWjD6facXKD/9KZvHxIL/aYYs0bteguOfA5T/wwxt8pFWiFEu7K/O1QtlFIM6eHHyj2prE5I\ns15D3P2NbpkHvgWPQFj9C1h5J1xIsV6bhBB2z27DHeCNu4czKjqQ/1hziP/ecBRTjdl6jekxAhZu\nhpv+BElb4Y1RsO3vxoVYIYRoY3Yd7r4ezvxzwQjmj4li2bYk7l+eQGG5FcPU0QnGPAaP7YE+k4wR\nOG+Pg9Rd1muTEMIuKa2tM6FFfHy8TkhI6LDPW7UnlT+sS6SHvwfv3BdP726d4A7U4xvhy/+AwjSI\nHgc9rzPuko0YIXfICiHqpZTap7WOv+p2Vwt3pVQ/4ONai3oBf9Rav1prGwW8BkwDyoD5Wuv9je23\no8MdYE9SPo98uI+qGjOv3z2cG67pBDclVZbA9tfgxJdwPhHQoByNi7GR1xphH3kt+IRau6VCiE6g\nzcK9zk4dgQxglNY6pdbyacDjGOE+CnhNaz2qsX1ZI9wB0i+U8eDyBE6eL+aZaTE8cH30leUJrKmi\nENL3Gt00qbsgPQFMlqGcfpFGyEeMAN8e4BNmPDwCZeSNEF1Ie4X7TcCzWuvr6ix/G9istV5peX0C\nGK+1PtfQvqwV7gCllSZ+s/oAXx85z5y4CF6cFYurUye8i/RikbOLYZ+6C0qzr9zG0QW8Q42gv/jz\n4iNyDHh3t07bhRDtoqnh3txx7ncCK+tZHg7UHm+YblnWYLhbk6erE2/dE8er35/iH9+f4mxuKYvv\njaObdxPLFHSU2kXOrn0UtDZuoCrKhKIMKDoHxZmW1+cg8yc4sRFMlrljndzh2l/DdU+Cm691j6Uh\n5w6CZ7B0OwnRxpp85q6UcgEygYFa6/N11m0AXtJab7O8/h74ndY6oc52C4GFAJGRkXEpKdYf6/2v\nQ+f47ScH8HN34cGx0dwxPAJ/TxdrN6vltDZmnbqQDLvehMOfGGPtx/4WRvwKnN2s3cLL9i2HDU+B\nVwgs+JdRX18I0ag275ZRSt0GPKq1vqmedTbVLVNXYkYhz64/wr6UC7g4OTB9UCh3j4okvqd/5+mP\nb6lzB+G75+HM9+ATARN+D0Pusm4xM61hy8uw6UWIGgvnj4CLJ8z/F/j3tF67hLAB7RHuq4Cvtdbv\n1bNuOvAYly+o/kNrPbKx/XWmcL/oeFYRK3ansnZ/BsWVJvoGe3HPqEhmDY/A193Z2s1rnaQtxrj6\njH3QLQYm/dGoctnRv7zMNcbwz71LjTLKt70O2Udh+a3g5gcLNoJvRMe2SQgb0qbhrpTyBFKBXlrr\nQsuyhwG01ostQyFfB6ZgDIVcULdLpq7OGO4XlVWZ2HDwHB/tSeVgWgFuzg7cMjiMu0dFMqyHn+2e\nzWsNx9YbtW7yTkOP0TD5Oeh5bcd8fnUFrF0IR9cZtfMnP2/U0wfI2A/vzwSPACPgfcI6pk1C2Jh2\nGS3TljpzuNeWmFHIij2prPspg9KqGmJCfXhoXC9uGxpmuyFfYzJKGG9+CUqyoNd4CB5ojKzxCrny\np5tf25zdVxTCqnsgeSvc/D/GBeK60hOMgPfubnTRyATmQvyMhHsbK6k0se5ABh/sTOF4VjEjowJ4\nYeZA+of4WLtpLVdVBrsXw4GPjNE21aU/38bJDby6G0Hr1d0YZz9odvPOrIuz4MPZkHMMZr4Fg+c2\nvG3qLvjgdqNrZv4G8Apu/nEJYcck3NuJ2axZnZDGn786TlGFifljonhqcl+83Wy8Tx6gshiKzxvD\nLUvOG6FckmUsK8mCwgzIPwMoiB4Lg+bCgBmND7PMPQ0fzoLSPJj3gVFT52qStxm/DAKi4b4N4BnY\n9GMwm+HcT+AX1bz3CWEjJNzb2YXSKv76zQlW7kklyMuV/5wWY9tdNU2VdwYOrYbDqyH/rDEpSb8p\nMHge9LnRqHl/UcY++GgOoOCeTyB8eNM/5+yPsGIuBPWFX643+uIborUxMUriGjj8KRSlQ8ggeOC7\nzjX0U4g2IOHeQQ6mFfCHdYkcSi9kZHQA/31bLP1CusBsS1ob4X1oNSR+CmW5Rv/8wFlGt0tVGaz+\nJXgGwS/WQmDv5n/G6e+N2vfBA+CX68C9znSJeWeMzz78CeSeBAcn6D0RwobBj382xvVPf7ltjleI\nTkLCvQPVmDUf703jL18fp7jCxIIxUTxpL101TVFTDWc2GWfzxzZcrocTMgju+bR1JRBOfgOr7obQ\nwcYviaoyOPKZEeiZPxnb9LwOYu+AATMvd8V8/Z+w83WYsxwGzmzd8QnRiUi4W0F+aRV//fo4q/am\n0c3Lld9N6c9NA7t3nZAHo8rl8X/BhSQY/Wtwa4MLzsc3GjNYeQRCSTagjQnHY2dD7O31j4s3VcF7\nU40z+oe2GP33QtgBCXcr+in1An9cd4TDGYU4KOgf4sPI6ABGRAUwItqfYG/pB262Y18YM1f1udEY\nrRPU9+rvuZACb4+FgN5w/9dXXg9ortJccPVp3T6EaAMS7lZWY9bsOpvHnqR89ibnsz/1AhXVxjR/\nUYEelqAPYGRUAD0DPez/Qqy1HPsCPr4XRj8KU/6nZfs4vhE+fcCorX/vZ5dvvBLCCiTcO5nqGjOJ\nGYXsTc5nT9IFElLyKSgzpvzr5u3KjQO6c9+1UV3jYmxH2/gfsOdtuHMl9J/W9PdpDbvegq+fMcb1\nF2UYc+COeaz92irEVUi4d3Jms+ZMTgl7kvPZdTafb45kUWkyM7pXAPPHRDM5JhgnRzlDbBOmSlh2\no9FN8/A28Otx9ffUmOCrRbD3Heh/C9y+BD5bCKe+gQe/Ny7wCmEFEu425kJpFav2pvHhrhQyCsoJ\n93Pn3tE9uXNED9suQdxZ5J2Bt2+A4Bijdo1jIxe5K4vhkwVw+lsY8zhMfsHoiinNg7fGGDdtLdwM\nLh4d1XohLpFwt1GmGjPfHctm+Y5kdp7Nw9XJgduGhnHfmCgGhnXSCTdsReKnsOZ+uO4puPH5+rcp\nTIcV8yD7mDFGPv7+K9ef+QE+mAUjHoTpf2v/NgtRR3vNxCTamZOjA1NiQ5gSG8KJrGKW70xm7f4M\nViekMyLKn3kjIunh746vhzN+7i74ujvj5uwgF2SbIvYOSNoK21+FqOuh741Xrs88YAR7VSncsxr6\nTP75PnpPhGsfM8bQ95lslE0WohOSM3cbUFhWzSf70nh/Zwqp+WU/W+/i5ICvuzN+7s74eTjj6+6M\nr7sLE/sHM21QiAR/bdXlsHSyUT/n4W2XC6BdHBHjEQh3r4buAxreh6kS3plkTHH4yE6Zp1Z0KOmW\nsUM1Zs2JrGIulFVRUFZNYXk1BeVVFJZXU1hWXWtZNTnFleSWVDKpfzD/PTOWMD93aze/88g5CUvG\nQ9hQo27N3nfgq98br+/6uGlhnX0cltxg3B17zxoZHik6jIR7F1dj1ry3PYmXvzmBk4MDv5van3tG\nRuLgIGfxABxcBWsfMkokZB22jIh5p3kXSfe8Axufhil/htEPt19bhailqeEupxt2ytFB8eDYXnzz\n1A0M6eHLHz5P5M4luziTU2LtpnUOQ+6EofcawT7mcZj7QfNHv4x4EK6ZAt/+0ZgHVohORM7cuwCt\nNZ/sS+fFDUepMJl5clJfFo7rhXNXH0dfUw05JyAktuX7KMkxhkd6BsGvfgBn6f4S7UvO3MUlSinm\nxvfgu9/ewOSYYP769QlmvL6dw+mF1m6adTk6ty7YAby6GbNLZR81JiAXopOQcO9Cgr3dePOeOBbf\nG0duSSW3vbGN/914jPKqGms3zbb1nQyjHjGmLDz1rXXbknUYyvKt2wbRKUi3TBdVWF7N/248xqq9\naYT7uTOhfzdGRAUwMjqAUF/pWmi26gp4ZwKU5hjDI726deznm82w5S/GpOehg+H+b2QWKjslo2VE\nk+w4ncviLWfZl5xPqeUMPtzP/VKJ4pHR/vTu5iVj5Zvi/BFYMgEiR8PY3xoh6+7f/p9bXmCM/Dn5\nFUTfAEk/QvwDcMsr7f/ZosNJuItmMdWYOZ5VfKlE8d7kfHJLqgDw93AmPsooTzwxJpje3bys3NpO\nLOFd2PAbwPL/yq+nMbFI2FDjZ8iQtj2rP3/EKGlckApTXjJG8Hz7R9jxD7h9KQye03afJToFCXfR\nKlprkvPK2JuUzx5L2KfkGXfHxvX0Z258BNMHh+HlKhUsfqY0F84dvPJxIenyep9wS9APNiYXDxvW\nss85vAbWPw6u3jD3feMvBjBGAS2/Fc4dMgqcdbumtUckOhEJd9HmsgorWH/QqHNzOrsEd2dHpg0K\nZW58BCOjA6TrpjHlBcbFztqBn3sS0BAeZ5xxD5zVtKGUNSb47lmjvk2P0TB3OXiHXLlNUSYsvh48\ng40hmlLB0m5IuIt2o7Xmp7QCPklI44uD5yipNBEV6MHsuAjuiIuQC7JNVV4Ah1bD3qWQe8Lonx/2\nC6MSZUNzvpbkwJoFkLwVRi40Jg9paOq/09/Dh3fA0Lth5pvtdxyiQ0m4iw5RVmXiq8QsVieksets\nPg4Kru/bjTtH9GDKwBApd9AUWhthvXcpHNsA2mxUrBzxoFF50sHR2C59nzFReFke3PIqDL3r6vve\n9D/w45/htjdg2L3texyiQ0i4iw6XmlfGmn1prNmXTmZhBbHhPvzX9AGM7hVo7abZjqJM2Lcc9v0T\nSrKMC7Lx94OLpzHdn3cIzPvQ6LNvCnMNfDAT0vYYM0i19qYtYXUS7sJqasyaLw5m8pevjpNZWMHN\nA7vz+6kxRAV5WrtptqOmGo5vgL3LjLN6MGrJ37EMPAKat6+SbKP/3dXbuMDqKvP02rI2DXellB+w\nFIjFGON1v9Z6Z63144F1wMUhAZ9prV9obJ8S7vavvKqGZdvO8ubmM1TXmPnltVE8MbEvvh6NTHEn\nfi77GOSdhn7TLnfRNFfyNmMEzcBZxi8Iufhts9o63JcDW7XWS5VSLoCH1rqg1vrxwNNa61ua2kAJ\n964ju7iCV745yccJafi6O/PUpL7cM7qnFC7raFv/Bt+/YEwPOOLBxretMRl/MRz9HE58BUF9jRuz\neo2XXwxW1mbhrpTyBQ4AvXQDG0u4i6Y4mlnEnzYeZfvpPHoFefLMtBgmxQTLEMqOYjbDynlwdjM8\n8M3Px9fXmCBlGxz5HI6tNy7cOntCn4nGxdziTAiPh3FPG6WO2/t70xq2/BWOroe7VoJfj/b9PBvR\nluE+FFgCHAWGAPuAJ7XWpbW2GQ98CqQDmRhB32iBawn3rklrzaYT2bz4r2OczSllTO9AbrimGyWV\nJoorTJRWmiixPIorjJ+llSZKKky4Ojvwn9NjmDk0XH4htFRZPiwea3TvPLQFXLwgZbtxhn50PZTl\nGoHebwoMmGmM2nF2N6YWPLACtv0dClKg+yAY91uImdHyrqLGVFcYN2gdXg3KEYIHwP1fgavcHd2W\n4R4P7AKu01rvVkq9BhRprf9QaxsfwKy1LlFKTQNe01r3rWdfC4GFAJGRkXEpKSnNOihhP6przKzY\nncqr353kQlk1SoGXqxPerk54uTnh6epkvHYzfnq5OnMg7QL7UwuYNiiEP80chL9nA+O7RePS9sJ7\nUyCoH5RmG8XOnD3hmpuNPvk+kxu+6anGBIlrjC6e3JMQaOmuGTTbKKHcFkpzYdU9kLYLJv4BQofC\nijnGNYe5H3T5KQ3bMtxDgF1a6yjL67HAIq319EbekwzEa61zG9pGztwFQJXJjMlsxt3Z8apn4zVm\nzdtbzvD3b0/i7+HCX2YPZny/4A5qqZ3Z847R/95nkiXQb2zeXazmGqPrZsvf4Pxh8IuE6/8Nht4D\nTq4tb1fOSSPIi87BrMUQe7uxfNdb8NUiGPs0TPpD4/uwc219QXUr8KDW+oRS6jnAU2v977XWhwDn\ntdZaKTUSWAP0bKiPHiTcRcsdySzk3z4+wMnzJfxidE9+P60/Hi5S48YqtIaTXxt94xkJ4B0K1z4K\ncfObP+Ty7I/GTVoOznDXKuhrABVbAAASDElEQVQx4srP+eIJ2P9+ly+I1tbhPhRjKKQLcBZYAMwD\n0FovVko9BjwCmIBy4Dda6x2N7VPCXbRGRXUNL399gmXbk4gK9OSVuUMYFtkB5XVF/bQ2Sg1v/Rsk\nbQE3P6M8wqiHjCkIr2b/B7DhKQjsA3d/DP5RP9/GVAUfzIL0vbBgI0RcNd/sktzEJLqEHWdyeXr1\nQc4XV/LYhD48NrGPDLG0tvR9sP3vRikFJzcY/ksY85jRdVOX2QzfPw/bX4VeE4wiaG6+De+7NM+Y\nFMVUYRRE841ov+PopCTcRZdRVFHNc+uP8Nn+DAZH+PL3eUOl5nxnkHMStr8Ghz426uUMmgPXPwXB\nMcb6qjJjkpFj6yFuAUz7a9MuymYfg6U3GsXV7v/KKM3QhUi4iy5n4+FzPLP2MBXVNcyOiyC+ZwBx\nPf2J8HeXoZPWVJgOO9806uVUlxqjXuIWwOb/hcyf4KYXjX765nxHJ7+GFfNgwAyY/c8uNYJGwl10\nSdlFFTz/xVE2ncimzDJtYJCXK3E9/Rge6U9cT39iw31xc26HsdmicWX5xiid3YuhPB+cPeCOpdC/\nwYF3jdvxf/DNf8ENv4MJz7RtWzsxCXfRpZlqzJw4X8z+1AL2p1xgf+qFSzNJOTsqBoT5Ehfpz6he\nAUzqH4yT9NN3nKpSOPyJcbdra6pUag3rHoMDH8LsdyH2jsa3N9dAznHI2GfcJBV3X+uGbVqJhLsQ\ndeSWVFqC3gj8g+kFVJrM9Az04NEJfZg1LFwuxtoaUyW8f5vRvbPgSwgfbizXGooyjCBPT4CM/cY2\n1aWX3xs6FOb8s+GJUTopCXchrqLKZOaH49n83w+nOJJZRIS/O49O6MMdwyNwcZKQtxklOfDORDBX\nQ/wDRohnJEDJeWO9o4sxX214nPGIiDcuyq77tfFL4LbXYcBt1j2GZpBwF6KJtNb8cDybf3x/ioPp\nhYT5uvHI+N7Mie8hffO2IisR3r0ZqkqMsfLh8ZYgj4PusfV3v1xIMaYszNgHox6GG1+wiW4aCXch\nmklrzZZTubz23Un2pxbQ3ceVh8b15u5RkRLytqAk2xhK6d6Mm9lMVcZk47vehLDhMOe9+m+g6kQk\n3IVoIa01O87k8dr3p9iTlE+QlysPjevFjKFhBHu7yrBKe3RsA3z+a+P5zDcg5lbrtqcREu5CtIFd\nZ/P4vx9Osf10HgDebk707uZFn2DLw/K8R4AHjjIZuG27kAyfzDf67Ef/GiY/D06dr/KohLsQbehQ\negE/pRZwOrvEeOSUkFNceWm9i5MDvYI86R3sxYBQH+4YHkGIr5sVWyxaxFQJ3z4Lu9+ydNP8E/x7\nWrtVV5BwF6KdFZZVczqnhDPZJZzJuRz6qfllOCrFLYNDuf/6aAZH+Fm7qaK5jq43xtAroP8txqQm\nLp7Gw9X78vPay71Dwav9S1BLuAthJSl5pSzfkcLqhDRKKk3E9/Tn/uujuWlAd7lZypbkJ8GGf4Pc\nU8YonKoSMJsa3l45GDdSjf3t5fo57UDCXQgrK66oZnVCOv/ckURafjnhfu7cN6Yn80ZE4uveRrMW\niY5lqroc9FWllofleeou2LvMuFEq5lYY9+8QOqTNmyDhLkQnUWPWfHfsPO9uS2J3Uj4eLo7Mjotg\n/pgoekn1SvtSlm/MGrX7bagshL43GyFfe+KRVpJwF6ITSswo5L3tyXxxMJOqGjM3D+zOU5OvISbU\nx9pNE22pohD2LDGqYZbnQ6/xRshHXd/qXUu4C9GJ5RRX8sHOZN7bnkxxpYmpsSE8Obkv/UMk5O1K\nZQkkvGtUsCzNhsgxMO5p6D2xeSWOa5FwF8IGFJZVs2zbWd7dnkxJpYnpg0J5cnJfrunezPlHRedW\nXW7M/7rtVSjONMbRT/nfFu1Kwl0IG1JQVsXSrUm8tz2Jsuoapg8K5anJfekTLCFvV0yVcHAlhAwy\nat+0gIS7EDboQmkV72w9yz93JFNeXcOMIWE8MamvTBsoLpFwF8KG5ZVUsmTrWd7fkUKlqYbbhobz\n6IQ+9AmWkO/qJNyFsAO5JZUs2XKWD3amUGGqYdqgUB6f2EcuvHZhEu5C2JG8kkqWbkvi/R3JlFbV\ncPPA7jw+sS+x4b7WbproYBLuQtihgrIq3t2ezHvbkyiuMDGxfzCPT+zDsMhm1DAXNk3CXQg7VlRR\nzfLtySzbnkRBWTVj+wbx+MS+jIwO+Nm2WmuKKkzkFFeQXVRJdnEl2cUVmDVMHxRKjwAPKxyBaCkJ\ndyG6gJJKEx/uSmHp1rPkllQxKjqAmFAfsosrOF9khHh2USWVJnO971cKxvXtxt2jIpnUP1gKm9kA\nCXchupDyqhpW7Ell6dazlFSY6ObjSrC3K8HebnT3MX4G+7jSzfvy8+IKEx/vTePjvamcL6qku48r\n8+J7MG9kJOF+7tY+JNEACXchRJOYasz8cDybFXtS+fFkDgoY3y+Yu0dGMr5fNzmb72Qk3IUQzZaW\nX2aczSekkVNcSaivG3Pje3DPqEiCfWRmqc6gTcNdKeUHLAViAQ3cr7XeWWu9Al4DpgFlwHyt9f7G\n9inhLkTnVV1j5vtj5/lodypbT+Xi4uTAvPgePHRDLyL85QKsNTU13J2auL/XgK+01rOVUi5A3W93\nKtDX8hgFvGX5KYSwQc6ODkyJDWVKbCjJuaW8veUMq/amsnJPKjOHhfPr8b2lFn0nd9Uzd6WUL3AA\n6KUb2Fgp9TawWWu90vL6BDBea32uof3KmbsQtiWzoJwlW86yck8qVTVmpg8K5dEJfaQWfQdr6pl7\nU66URAM5wHtKqZ+UUkuVUp51tgkH0mq9TrcsE0LYiTA/d56bMZBtv5vIQ+N6s+l4NlNf28qDyxM4\nkFZg7eaJOpoS7k7AcOAtrfUwoBRY1JIPU0otVEolKKUScnJyWrILIYSVdfN2ZdHU/mxfNJGnJvdl\nb3I+M9/Yzr1Ld7PjdC5ms3UGaYgrNaVbJgTYpbWOsrweCyzSWk+vtY10ywjRRZVUmvhoVwrvWG6k\nCvN149YhYdw6JIyBYT6oFs44JOrXZhdUtdZZSqk0pVQ/rfUJYBJwtM5m64HHlFKrMC6kFjYW7EII\n++Hl6sRDN/TmvjFRfJWYxfqDmSzblsTbW87SK8iTW4aEMWNImJQr7mBNHQo5FGMopAtwFlgAzAPQ\nWi+2DIV8HZiCMRRygda60dNyOXMXwn4VlFXxZWIW6w9ksispD60hJtSHGUPCuHVIqAynbAW5iUkI\n0SlkF1Ww4dA5vjiUyU+pxoXX4ZF+zBgSxvTBYXTzdrVyC22LhLsQotNJyy9j/cFMvjiYyfGsYhwU\nXNcniBlDwrg5NgQfN2drN7HTk3AXQnRqJ88Xs/5AJusOZpCWX46LkwMT+nXjtqHhTOwfjJuzo7Wb\n2ClJuAshbILWmgNpBaw/mMmGQ+fIKa7Ey9WJmwZ2Z8aQMK7rE4SzFC+7RMJdCGFzasyaXWfzWH8g\nk42J5yiuMOHt5kRsmC8DwnwYGObDwDBfenfz7LLVKiXchRA2rdJUw48ncth8MocjmUUcP1d0adIR\nFycH+od4MyDUCPwBYT70D/HB07Wp5bJsl4S7EMKumGrMJOWWciSziCOZhRw9V8SRzCIKyqoBY1ap\n8dd049EJfYiP+vl0g/ZCwl0IYfe01pwrrOBIZhE/pV5g1d408kurGBkdwGMT+jC2b5Dd3SEr4S6E\n6HLKq2pYuSeVJVvOklVUweAIX349vg83DeiOg4N9hLyEuxCiy6o01bB2fwZv/XiGlLwy+gZ78esJ\nvbl1cJjNX4iVcBdCdHmmGjP/OnyONzed4cT5YnoEuPPwDb2ZHReBq5NtjqOXcBdCCAuzWfP98Wxe\n33Sag2kFdPN2ZU5cBHPjexAVVHd6is5Nwl0IIerQWrP9dB7/3JHED8ezMWu4tlcg80b0YEpsiE3c\nFSvhLoQQjcgqrODT/el8vDeN1PwyfNycmDUsnHkjIhkQ1nmnDpRwF0KIJjCbNbuS8vh4bxpfJmZR\nZTIzOMKXufE9mDE0rNMVM5NwF0KIZiooq2LdgUxW7knleFYxbs4OXN8niJHRAYyMDiQ2zMfqo20k\n3IUQooW01hzOKOSThHS2n87lbG4pAJ4ujgzv6c/oXoGMjA5gcIRvh4+6abNp9oQQoqtRSjE4wo/B\nEX6AMeHInuR8dp/NZ09SPn/9+gQArk4ODIv0Y2R0IOP6BhHX07/T3BErZ+5CCNFM+aVV7L0Y9sl5\nHM0swqxhZHQA/35zP0a0Y20b6ZYRQogOUlRRzdr9Gby+6TQ5xZWM79eNp2/qR2y4b5t/loS7EEJ0\nsPKqGpbvTGbxj2coKKtmamwIv7nxGvp2926zz5BwF0IIKymqqGbZ1iSWbUuitMrErKHhPDm5Lz0D\nW383rIS7EEJY2YXSKhb/eIblO5Mx1WjmxPfgiUl9CPV1b/E+JdyFEKKTyC6q4I1Np1mxJxWlFP9x\ncz8eHNurRftqarjbdu1LIYSwAcE+bjx/Wyybnh7PzKFhRPh7tPtnyjh3IYToIBH+Hvxl9pAO+Sw5\ncxdCCDsk4S6EEHZIwl0IIeyQhLsQQtghCXchhLBDTRoto5RKBoqBGsBUd4ylUmo8sA5Isiz6TGv9\nQts1UwghRHM0ZyjkBK11biPrt2qtb2ltg4QQQrSedMsIIYQdauqZuwa+UUpp4G2t9ZJ6trlWKXUQ\nyASe1lofqbuBUmohsNDyskQpdaIljQaCgMb+irBF9nZM9nY8YH/HZG/HA/Z3TPUdT8+mvLFJtWWU\nUuFa6wylVDDwLfC41npLrfU+gFlrXaKUmga8prXu2+TmN5NSKqEptRVsib0dk70dD9jfMdnb8YD9\nHVNrjqdJ3TJa6wzLz2xgLTCyzvoirXWJ5flGwFkpFdSSBgkhhGi9q4a7UspTKeV98TlwE5BYZ5sQ\nZZk4UCk10rLfvLZvrhBCiKZoSp97d2CtJbudgBVa66+UUg8DaK0XA7OBR5RSJqAcuFO3by3h+vr8\nbZ29HZO9HQ/Y3zHZ2/GA/R1Ti4/HavXchRBCtB8ZCimEEHbI5sJdKTVFKXVCKXVaKbXI2u1pC0qp\nZKXUYaXUAaWUzU1PpZR6VymVrZRKrLUsQCn1rVLqlOWnvzXb2FwNHNNzSqkMy/d0wDIyzCYopXoo\npTYppY4qpY4opZ60LLfJ76mR47Hl78hNKbVHKXXQckzPW5ZHK6V2WzLvY6WUS5P2Z0vdMkopR+Ak\ncCOQDuwF7tJaH7Vqw1rJUt4h/ip3AHdaSqlxQAnwvtY61rLsL0C+1volyy9hf63176zZzuZo4Jie\nA0q01i9bs20toZQKBUK11vstAyT2ATOB+djg99TI8czFdr8jBXhahpQ7A9uAJ4HfYJR0WaWUWgwc\n1Fq/dbX92dqZ+0jgtNb6rNa6ClgF3GblNnV5lnse8ussvg1Ybnm+HOM/ns1o4Jhsltb6nNZ6v+V5\nMXAMCMdGv6dGjsdmaUOJ5aWz5aGBicAay/Imf0e2Fu7hQFqt1+nY+BdqcfEO4H2Wu3jtQXet9TnL\n8yyMUVf24DGl1CFLt41NdGHUpZSKAoYBu7GD76nO8YANf0dKKUel1AEgG+OG0TNAgdbaZNmkyZln\na+Fur67XWg8HpgKPWroE7IZlWKzt9P817C2gNzAUOAf8zbrNaT6llBfwKfCU1rqo9jpb/J7qOR6b\n/o601jVa66FABEZPRf+W7svWwj0D6FHrdYRlmU272h3ANuq8pV/0Yv9otpXb02pa6/OW/3xm4B1s\n7Huy9ON+Cnyktf7Msthmv6f6jsfWv6OLtNYFwCbgWsBPKXXxnqQmZ56thfteoK/l6rELcCew3spt\napWm3AFso9YD91me34dR79+mXQxBi1nY0PdkuVi3DDimtX6l1iqb/J4aOh4b/466KaX8LM/dMQaO\nHMMI+dmWzZr8HdnUaBkAy9CmVwFH4F2t9Z+s3KRWUUr1wjhbh8t3ANvUMSmlVgLjMSrYnQeeBT4H\nVgORQAowV2ttMxcoGzim8Rh/7msgGXioVn91p6aUuh7YChwGzJbFz2D0U9vc99TI8dyF7X5HgzEu\nmDpinHiv1lq/YMmIVUAA8BNwr9a68qr7s7VwF0IIcXW21i0jhBCiCSTchRDCDkm4CyGEHZJwF0II\nOyThLoQQdkjCXQgh7JCEuxBC2CEJdyGEsEP/D8ukqwa8jcqEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xQVCiaNDn4VJ"
      },
      "source": [
        "As you can see in the above plot, the validation loss stopped decreasing after 5 epochs. It did improve but not very significant.So, we didn't get very good results from our basic model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FgePSmZBmSbn"
      },
      "source": [
        "# 6)-Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6gh_CukCl7Al",
        "colab": {}
      },
      "source": [
        "model = load_model('model_translate.h1') \n",
        "\n",
        "preds = model.predict_classes(testX.reshape((testX.shape[0], testX.shape[1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M-DaR0x4oA4P"
      },
      "source": [
        "These predictions are sequences of integers. We need to convert these integers to their corresponding words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VU6IOmOOoB3f"
      },
      "source": [
        "### 6.1)- Convert integers to words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oiy9gGAAmAat",
        "colab": {}
      },
      "source": [
        "def get_word(n, tokenizer):  \n",
        "      for word, index in tokenizer.word_index.items():                       \n",
        "          if index == n: \n",
        "              return word \n",
        "      return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KqSwZTcXmDTW"
      },
      "source": [
        "### 6.2)-Convert predictions into text (German)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y82jlYQMmAg0",
        "colab": {}
      },
      "source": [
        "preds_text = [] \n",
        "for i in preds:        \n",
        "       temp = []        \n",
        "       for j in range(len(i)):             \n",
        "            t = get_word(i[j], deu_tokenizer)             \n",
        "            if j > 0:                 \n",
        "                if (t==get_word(i[j-1],deu_tokenizer))or(t== None):                       \n",
        "                     temp.append('')                 \n",
        "                else:                      \n",
        "                     temp.append(t)             \n",
        "            else:                    \n",
        "                if(t == None):                                   \n",
        "                     temp.append('')                    \n",
        "                else:                           \n",
        "                     temp.append(t)        \n",
        "       preds_text.append(' '.join(temp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XOAI5cB8mAj3",
        "colab": {}
      },
      "source": [
        "pred_df = pd.DataFrame({'actual' : test[:,1], 'predicted' : preds_text})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S2orsrv6oo4o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "b6ea08e3-c407-46fb-9aef-6632370f2a13"
      },
      "source": [
        "# 1st 5 rows\n",
        "pred_df.head(5)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wahrend die konkurrenz naher ruckt und neue technologien alte bequeme sicherheiten bedrohen ist die anstehende verhandlung der lizenzgebuhren fur die bbc mit besonderen gefahren verbunden</td>\n",
              "      <td>und die   der  zu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>luther rabinowitz lie seine pyramide zusammenfallen</td>\n",
              "      <td>ich war in ein fur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kurzlich erklarten die gesundheitsbehorden die krankheit sei in jeden winkel des landes vorgedrungen</td>\n",
              "      <td>und die   und der zu war</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ich billige den tweet nicht und habe ihn geloscht hie es in der spateren nachricht</td>\n",
              "      <td>und       war</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fur den chef des oberurseler kultkiosks gehoren radtouren uber den feldberg einfach dazu</td>\n",
              "      <td>und die   und der zu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                        actual                 predicted\n",
              "0  wahrend die konkurrenz naher ruckt und neue technologien alte bequeme sicherheiten bedrohen ist die anstehende verhandlung der lizenzgebuhren fur die bbc mit besonderen gefahren verbunden        und die   der  zu \n",
              "1                                                                                                                                          luther rabinowitz lie seine pyramide zusammenfallen     ich war in ein fur   \n",
              "2                                                                                         kurzlich erklarten die gesundheitsbehorden die krankheit sei in jeden winkel des landes vorgedrungen  und die   und der zu war\n",
              "3                                                                                                           ich billige den tweet nicht und habe ihn geloscht hie es in der spateren nachricht             und       war\n",
              "4                                                                                                     fur den chef des oberurseler kultkiosks gehoren radtouren uber den feldberg einfach dazu     und die   und der zu "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LPocsO00mJy-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "4186cb0f-a6b1-4f7d-ce39-a6bdee571512"
      },
      "source": [
        "# print 5 rows randomly \n",
        "pred_df.sample(5)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>dass es auch ohne rad locker nach oben ging bewiesen nicht nur die wanderer die uber die weie mauer und den fuchstanz zum gipfel hinauf stiegen sondern auch ein jogger der an einer kordel einen au...</td>\n",
              "      <td>und     der war</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1164</th>\n",
              "      <td>ich wollte fur mein land kampfen aber das wird nicht geschehen</td>\n",
              "      <td>ich     nicht</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>853</th>\n",
              "      <td>es ist so schwierig sich an alle orte zu erinnern an denen man gearbeitet hat und an die daten</td>\n",
              "      <td>und die und    zu war</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>816</th>\n",
              "      <td>pascal perrineau ein politikwissenschaftler an der sciences po universitat warnte davor dass die franzosen schnell die geduld verlieren wurde wenn die neue sozialistische regierung keine verbesser...</td>\n",
              "      <td>und die  und  der zu wurde</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>ich hoffe dass frauen die einen anderen aber parallelen grund dafur haben eine dem korper innewohnende gefahr zu verstehen und meinungen zur rasse die in offentlichen umfragen deutlich anders sind...</td>\n",
              "      <td>und die  und  der zu wurde</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                       actual                   predicted\n",
              "751   dass es auch ohne rad locker nach oben ging bewiesen nicht nur die wanderer die uber die weie mauer und den fuchstanz zum gipfel hinauf stiegen sondern auch ein jogger der an einer kordel einen au...            und     der war \n",
              "1164                                                                                                                                           ich wollte fur mein land kampfen aber das wird nicht geschehen             ich     nicht  \n",
              "853                                                                                                            es ist so schwierig sich an alle orte zu erinnern an denen man gearbeitet hat und an die daten       und die und    zu war\n",
              "816   pascal perrineau ein politikwissenschaftler an der sciences po universitat warnte davor dass die franzosen schnell die geduld verlieren wurde wenn die neue sozialistische regierung keine verbesser...  und die  und  der zu wurde\n",
              "408   ich hoffe dass frauen die einen anderen aber parallelen grund dafur haben eine dem korper innewohnende gefahr zu verstehen und meinungen zur rasse die in offentlichen umfragen deutlich anders sind...  und die  und  der zu wurde"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z0LG2ydWrci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}