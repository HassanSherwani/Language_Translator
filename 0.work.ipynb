{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_t3V5W67K5zX"
   },
   "source": [
    "# Machine Translation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Q5A1ySzLPrq"
   },
   "source": [
    "# 1)- Importing key modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dPBH2WUkKwz-"
   },
   "outputs": [],
   "source": [
    "#support both Python 2 and Python 3 with minimal overhead.\n",
    "from __future__ import absolute_import, division, print_function\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>body {\n",
       "    margin: 0;\n",
       "    font-family: Helvetica;\n",
       "}\n",
       "table.dataframe {\n",
       "    border-collapse: collapse;\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe tr {\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe td, table.dataframe th {\n",
       "    margin: 0;\n",
       "    border: 1px solid white;\n",
       "    padding-left: 0.25em;\n",
       "    padding-right: 0.25em;\n",
       "}\n",
       "table.dataframe th:not(:empty) {\n",
       "    background-color: #fec;\n",
       "    text-align: left;\n",
       "    font-weight: normal;\n",
       "}\n",
       "table.dataframe tr:nth-child(2) th:empty {\n",
       "    border-left: none;\n",
       "    border-right: 1px dashed #888;\n",
       "}\n",
       "table.dataframe td {\n",
       "    border: 2px solid #ccf;\n",
       "    background-color: #f4f4ff;\n",
       "}\n",
       "h3 {\n",
       "    color: white;\n",
       "    background-color: black;\n",
       "    padding: 0.5em;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's life without style :). So, let's add style to our dataframes\n",
    "from IPython.core.display import HTML\n",
    "css = open('style-table.css').read() + open('style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zTJY_mj6K-LS"
   },
   "outputs": [],
   "source": [
    "import string \n",
    "from string import digits\n",
    "from collections import Counter\n",
    "import re \n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd \n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "from unicodedata import normalize\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import re \n",
    "from numpy import array, argmax, random, take \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model \n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.6.3 64bit [MSC v.1900 64 bit (AMD64)]"
        },
        {
         "module": "IPython",
         "version": "7.4.0"
        },
        {
         "module": "OS",
         "version": "Windows 10 10.0.16299 SP0"
        },
        {
         "module": "pandas",
         "version": "0.23.4"
        },
        {
         "module": "re",
         "version": "2.2.1"
        },
        {
         "module": "sklearn",
         "version": "0.20.3"
        },
        {
         "module": "matplotlib",
         "version": "2.1.0"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.3 64bit [MSC v.1900 64 bit (AMD64)]</td></tr><tr><td>IPython</td><td>7.4.0</td></tr><tr><td>OS</td><td>Windows 10 10.0.16299 SP0</td></tr><tr><td>pandas</td><td>0.23.4</td></tr><tr><td>re</td><td>2.2.1</td></tr><tr><td>sklearn</td><td>0.20.3</td></tr><tr><td>matplotlib</td><td>2.1.0</td></tr><tr><td colspan='2'>Thu Sep 12 18:29:04 2019 W. Europe Daylight Time</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.6.3 64bit [MSC v.1900 64 bit (AMD64)] \\\\ \\hline\n",
       "IPython & 7.4.0 \\\\ \\hline\n",
       "OS & Windows 10 10.0.16299 SP0 \\\\ \\hline\n",
       "pandas & 0.23.4 \\\\ \\hline\n",
       "re & 2.2.1 \\\\ \\hline\n",
       "sklearn & 0.20.3 \\\\ \\hline\n",
       "matplotlib & 2.1.0 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Thu Sep 12 18:29:04 2019 W. Europe Daylight Time} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.6.3 64bit [MSC v.1900 64 bit (AMD64)]\n",
       "IPython 7.4.0\n",
       "OS Windows 10 10.0.16299 SP0\n",
       "pandas 0.23.4\n",
       "re 2.2.1\n",
       "sklearn 0.20.3\n",
       "matplotlib 2.1.0\n",
       "Thu Sep 12 18:29:04 2019 W. Europe Daylight Time"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first install: pip install version_information\n",
    "%reload_ext version_information\n",
    "%version_information pandas,re,sklearn, matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-X0sC5fLS7a"
   },
   "source": [
    "# 2)- Loading data\n",
    "\n",
    "We have data from 2009 to 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFpuPSdKLEtJ"
   },
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3QpycswrLlaU"
   },
   "outputs": [],
   "source": [
    "# split a loaded document into sentences\n",
    "def to_sentences(doc):\n",
    "\treturn doc.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GMLe1Lk5LnAV"
   },
   "outputs": [],
   "source": [
    "# shortest and longest sentence lengths\n",
    "def sentence_lengths(sentences):\n",
    "\tlengths = [len(s.split()) for s in sentences]\n",
    "\treturn min(lengths), max(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lkrmOs7-L0X0"
   },
   "source": [
    "### 2.1)- For year 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Xg8f11ToLpnc",
    "outputId": "311de7c7-f649-42f0-8cd9-ec431b5807f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=2525, min=1, max=108\n",
      "German data: sentences=2525, min=1, max=110\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2009.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load French data\n",
    "filename = 'newstest2009.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQmRuUHGL74N"
   },
   "source": [
    "It is important to notice that sentence length is same. So, we have a balanced data.\n",
    "\n",
    "We shall check this on all years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lr3hYKrBMGtQ"
   },
   "source": [
    "### 2.2)-For 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "bF2HZBV-LycJ",
    "outputId": "acdf8664-6604-4301-8d9d-ba390eaf4347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=2489, min=1, max=74\n",
      "German data: sentences=2489, min=1, max=86\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2010.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load French data\n",
    "filename = 'newstest2010.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xFaKT4WENIA0"
   },
   "source": [
    "### 2.3)-For year 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "OFdlOFxaM8GF",
    "outputId": "36ee1165-5d13-4dab-84dc-23b0f15cf953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=3003, min=1, max=93\n",
      "German data: sentences=3003, min=1, max=92\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2011.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load French data\n",
    "filename = 'newstest2011.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-iKcf42NQl9"
   },
   "source": [
    "### 2.4)-For year 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "T6YRzm6yNO12",
    "outputId": "9b944f1f-774e-458a-9039-0ccffa67ab29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=3003, min=1, max=114\n",
      "German data: sentences=3003, min=1, max=101\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2012.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load French data\n",
    "filename = 'newstest2012.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4624P_5XNUCW"
   },
   "source": [
    "### 2.5)-For year 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6pqUQn_dNW8B",
    "outputId": "b7324f03-847e-44b7-9548-e0a01f752c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=3000, min=1, max=82\n",
      "German data: sentences=3000, min=1, max=85\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2013.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load French data\n",
    "filename = 'newstest2013.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ROs3kgYNXzl"
   },
   "source": [
    "### 2.6)-For year 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "ZlS9fS1ANcTU",
    "outputId": "b6621ab2-a139-465e-96ce-f3f0fe6040bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=3003, min=1, max=68\n",
      "German data: sentences=3003, min=1, max=64\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2014.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load French data\n",
    "filename = 'newstest2014.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_By95YGUOKjP"
   },
   "source": [
    "### 2.7)- For year 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Id289Xi1ONBv",
    "outputId": "d7d9604d-c494-4b87-b9c8-47cc10ba9d87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=2169, min=1, max=71\n",
      "German data: sentences=2169, min=1, max=72\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2015.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load French data\n",
    "filename = 'newstest2015.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VzgjV6OjON2G"
   },
   "source": [
    "### For year 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "z2fUwxLLOQFR",
    "outputId": "53495f34-d4a9-4c63-a113-e531e115c426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English data: sentences=2999, min=1, max=83\n",
      "German data: sentences=2999, min=1, max=88\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2016.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
    "\n",
    "# load French data\n",
    "filename = 'newstest2016.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "minlen, maxlen = sentence_lengths(sentences)\n",
    "print('German data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Jlgba1dOkje"
   },
   "source": [
    "**All datasets have balanced sentences for English and German version**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "351hNk4lOsGe"
   },
   "source": [
    "# 3)- Data Cleaning\n",
    "\n",
    "- Tokenizing text by white space.\n",
    "- Normalizing case to lowercase.\n",
    "- Removing punctuation from each word.\n",
    "- Removing non-printable characters.\n",
    "- Removing words that contain non-alphabetic characters.\n",
    "\n",
    "\n",
    "**We shall use only one file(2015) for quick processing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4XeL-PkOh7o"
   },
   "outputs": [],
   "source": [
    "# create cleaning function\n",
    "\n",
    "def clean_lines(lines):\n",
    "\tcleaned = list()\n",
    "\t# prepare regex for char filtering\n",
    "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "\t# prepare translation table for removing punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\tfor line in lines:\n",
    "\t\t# normalize unicode characters\n",
    "\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "\t\tline = line.decode('UTF-8')\n",
    "\t\t# tokenize on white space\n",
    "\t\tline = line.split()\n",
    "\t\t# convert to lower case\n",
    "\t\tline = [word.lower() for word in line]\n",
    "\t\t# remove punctuation from each token\n",
    "\t\tline = [word.translate(table) for word in line]\n",
    "\t\t# remove non-printable chars form each token\n",
    "\t\tline = [re_print.sub('', w) for w in line]\n",
    "\t\t# remove tokens with numbers in them\n",
    "\t\tline = [word for word in line if word.isalpha()]\n",
    "\t\t# store as string\n",
    "\t\tcleaned.append(' '.join(line))\n",
    "\treturn cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXXFMVdbQIIs"
   },
   "outputs": [],
   "source": [
    "# save a list of clean sentences to file\n",
    "def save_clean_sentences(sentences, filename):\n",
    "\tdump(sentences, open(filename, 'wb'))\n",
    "\tprint('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uaYHZmrgQMJ0",
    "outputId": "2e3c9597-9a43-4c9f-f9b9-a577c0f73775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english2015.pkl\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2015.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'english2015.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "id": "Tb9xfJXJQeGX",
    "outputId": "9b1244e5-8d65-4cad-cc09-be937c555f71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india and japan prime ministers meet in tokyo\n",
      "indias new prime minister narendra modi is meeting his japanese counterpart shinzo abe in tokyo to discuss economic and security ties on his first major foreign visit since winning mays election\n",
      "mr modi is on a fiveday trip to japan to strengthen economic ties with the third largest economy in the world\n",
      "high on the agenda are plans for greater nuclear cooperation\n",
      "india is also reportedly hoping for a deal on defence collaboration between the two nations\n",
      "karratha police arrest after high speed motorcycle chase\n",
      "a motorcycle has been seized after it was ridden at in a zone and through bushland to escape police in the pilbara\n",
      "traffic police on patrol in karratha this morning tried to pull over a blue motorcycle when they spotted it reaching as it pulled out of a service station on bathgate road\n",
      "police say the rider then failed to stop and continued on to burgess road before turning into bushland causing the officers to lose sight of it\n",
      "the motorcycle and a person matching the description of the rider was then spotted at a house on walcott way in bulgarra\n"
     ]
    }
   ],
   "source": [
    "# spot check for english version\n",
    "for i in range(10):\n",
    "\tprint(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "Wryy3Y1OQVDv",
    "outputId": "67adf2b8-d1a3-4b46-9715-d5d04f40f3ae",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: german2015.pkl\n",
      "die premierminister indiens und japans trafen sich in tokio\n",
      "indiens neuer premierminister narendra modi trifft bei seinem ersten wichtigen auslandsbesuch seit seinem wahlsieg im mai seinen japanischen amtskollegen shinzo abe in toko um wirtschaftliche und sicherheitspolitische beziehungen zu besprechen\n",
      "herr modi befindet sich auf einer funftagigen reise nach japan um die wirtschaftlichen beziehungen mit der drittgroten wirtschaftsnation der welt zu festigen\n",
      "plane fur eine starkere kerntechnische zusammenarbeit stehen ganz oben auf der tagesordnung\n",
      "berichten zufolge hofft indien daruber hinaus auf einen vertrag zur verteidigungszusammenarbeit zwischen den beiden nationen\n",
      "polizei von karratha verhaftet nach schneller motorradjagd\n",
      "ein motorrad wurde beschlagnahmt nachdem der fahrer es mit kmh in einer kmhzone und durch buschland gefahren hatte um der polizei in bilbara zu entkommen\n",
      "verkehrspolizisten in karratha versuchten heute morgen ein blaues motorrad zu stoppen nachdem sie es dabei beobachtet hatten wie es mit kmh eine tankstelle auf der bathdate road verlie\n",
      "die polizei berichtet dass der fahrer die haltesignale dann ignorierte und weiter auf der burgess road fuhr bevor er in das buschland abbog wo die beamten es aus den augen verloren\n",
      "das motorrad sowie eine person die der beschreibung des fahrers entsprach wurden spater bei einem haus im walcott way in bulgarra gesehen\n"
     ]
    }
   ],
   "source": [
    "# load and check German data\n",
    "\n",
    "filename = 'newstest2015.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'german2015.pkl')\n",
    "# spot check for german version\n",
    "for i in range(10):\n",
    "\tprint(sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4)- Vocab frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "\treturn load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vocab(lines):\n",
    "\tvocab = Counter()\n",
    "\tfor line in lines:\n",
    "\t\ttokens = line.split()\n",
    "\t\tvocab.update(tokens)\n",
    "\treturn vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a)-original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary: 7227\n"
     ]
    }
   ],
   "source": [
    "# load English dataset i.e pickled earlier\n",
    "filename = 'english2015.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "\n",
    "# calculate vocabulary\n",
    "vocab = to_vocab(lines)\n",
    "print('English Vocabulary: %d' % len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German Vocabulary: 9280\n"
     ]
    }
   ],
   "source": [
    "# load German dataset i.e pickled earlier\n",
    "filename = 'german2015.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "# calculate vocabulary\n",
    "vocab = to_vocab(lines)\n",
    "print('German Vocabulary: %d' % len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5)-For pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_eng= pd.read_pickle('english2015.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_clean_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['india and japan prime ministers meet in tokyo',\n",
       " 'indias new prime minister narendra modi is meeting his japanese counterpart shinzo abe in tokyo to discuss economic and security ties on his first major foreign visit since winning mays election',\n",
       " 'mr modi is on a fiveday trip to japan to strengthen economic ties with the third largest economy in the world',\n",
       " 'high on the agenda are plans for greater nuclear cooperation',\n",
       " 'india is also reportedly hoping for a deal on defence collaboration between the two nations']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_eng[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_eng=pd.DataFrame(df_clean_eng, columns=['eng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>india and japan prime ministers meet in tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indias new prime minister narendra modi is meeting his japanese counterpart shinzo abe in tokyo to discuss economic and security ties on his first major foreign visit since winning mays election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mr modi is on a fiveday trip to japan to strengthen economic ties with the third largest economy in the world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high on the agenda are plans for greater nuclear cooperation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>india is also reportedly hoping for a deal on defence collaboration between the two nations</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                  eng\n",
       "0                                                                                                                                                       india and japan prime ministers meet in tokyo\n",
       "1  indias new prime minister narendra modi is meeting his japanese counterpart shinzo abe in tokyo to discuss economic and security ties on his first major foreign visit since winning mays election\n",
       "2                                                                                       mr modi is on a fiveday trip to japan to strengthen economic ties with the third largest economy in the world\n",
       "3                                                                                                                                        high on the agenda are plans for greater nuclear cooperation\n",
       "4                                                                                                         india is also reportedly hoping for a deal on defence collaboration between the two nations"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2169, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_eng.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save as of text file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_eng.to_csv(r'english2015.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b)- for german"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_ger= pd.read_pickle('german2015.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_clean_ger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ger=pd.DataFrame(df_clean_ger, columns=['ger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>die premierminister indiens und japans trafen sich in tokio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indiens neuer premierminister narendra modi trifft bei seinem ersten wichtigen auslandsbesuch seit seinem wahlsieg im mai seinen japanischen amtskollegen shinzo abe in toko um wirtschaftliche und ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>herr modi befindet sich auf einer funftagigen reise nach japan um die wirtschaftlichen beziehungen mit der drittgroten wirtschaftsnation der welt zu festigen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plane fur eine starkere kerntechnische zusammenarbeit stehen ganz oben auf der tagesordnung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>berichten zufolge hofft indien daruber hinaus auf einen vertrag zur verteidigungszusammenarbeit zwischen den beiden nationen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                       ger\n",
       "0                                                                                                                                              die premierminister indiens und japans trafen sich in tokio\n",
       "1  indiens neuer premierminister narendra modi trifft bei seinem ersten wichtigen auslandsbesuch seit seinem wahlsieg im mai seinen japanischen amtskollegen shinzo abe in toko um wirtschaftliche und ...\n",
       "2                                            herr modi befindet sich auf einer funftagigen reise nach japan um die wirtschaftlichen beziehungen mit der drittgroten wirtschaftsnation der welt zu festigen\n",
       "3                                                                                                              plane fur eine starkere kerntechnische zusammenarbeit stehen ganz oben auf der tagesordnung\n",
       "4                                                                             berichten zufolge hofft indien daruber hinaus auf einen vertrag zur verteidigungszusammenarbeit zwischen den beiden nationen"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ger.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2169, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ger.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save as text file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ger.to_csv(r'german2015.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2169, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combine_2015_clean=pd.concat([new_eng, new_ger], axis=1, join='inner') # to adjust automatically row labels i.e index\n",
    "df_combine_2015_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>ger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>india and japan prime ministers meet in tokyo</td>\n",
       "      <td>die premierminister indiens und japans trafen sich in tokio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indias new prime minister narendra modi is meeting his japanese counterpart shinzo abe in tokyo to discuss economic and security ties on his first major foreign visit since winning mays election</td>\n",
       "      <td>indiens neuer premierminister narendra modi trifft bei seinem ersten wichtigen auslandsbesuch seit seinem wahlsieg im mai seinen japanischen amtskollegen shinzo abe in toko um wirtschaftliche und ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mr modi is on a fiveday trip to japan to strengthen economic ties with the third largest economy in the world</td>\n",
       "      <td>herr modi befindet sich auf einer funftagigen reise nach japan um die wirtschaftlichen beziehungen mit der drittgroten wirtschaftsnation der welt zu festigen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high on the agenda are plans for greater nuclear cooperation</td>\n",
       "      <td>plane fur eine starkere kerntechnische zusammenarbeit stehen ganz oben auf der tagesordnung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>india is also reportedly hoping for a deal on defence collaboration between the two nations</td>\n",
       "      <td>berichten zufolge hofft indien daruber hinaus auf einen vertrag zur verteidigungszusammenarbeit zwischen den beiden nationen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                  eng  \\\n",
       "0                                                                                                                                                       india and japan prime ministers meet in tokyo   \n",
       "1  indias new prime minister narendra modi is meeting his japanese counterpart shinzo abe in tokyo to discuss economic and security ties on his first major foreign visit since winning mays election   \n",
       "2                                                                                       mr modi is on a fiveday trip to japan to strengthen economic ties with the third largest economy in the world   \n",
       "3                                                                                                                                        high on the agenda are plans for greater nuclear cooperation   \n",
       "4                                                                                                         india is also reportedly hoping for a deal on defence collaboration between the two nations   \n",
       "\n",
       "                                                                                                                                                                                                       ger  \n",
       "0                                                                                                                                              die premierminister indiens und japans trafen sich in tokio  \n",
       "1  indiens neuer premierminister narendra modi trifft bei seinem ersten wichtigen auslandsbesuch seit seinem wahlsieg im mai seinen japanischen amtskollegen shinzo abe in toko um wirtschaftliche und ...  \n",
       "2                                            herr modi befindet sich auf einer funftagigen reise nach japan um die wirtschaftlichen beziehungen mit der drittgroten wirtschaftsnation der welt zu festigen  \n",
       "3                                                                                                              plane fur eine starkere kerntechnische zusammenarbeit stehen ganz oben auf der tagesordnung  \n",
       "4                                                                             berichten zufolge hofft indien daruber hinaus auf einen vertrag zur verteidigungszusammenarbeit zwischen den beiden nationen  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combine_2015_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save work as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine_2015_clean.to_pickle('data_2015_clean_preprocess.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine_2015_clean.to_csv('data_2015_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save as text file too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combine_2015_clean.to_csv(r'data_2015_clean.txt', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use np.......\n",
    "\n",
    "np.savetxt(r'data_2015_clean_np.txt', df_combine_2015_clean.eng+df_combine_2015_clean.ger , fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6)- Combining all files from 2009-2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a.All english versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english2009.pkl\n",
      "prague stock market falls to minus by the end of the trading day\n",
      "after a sharp drop in the morning the prague stock market corrected its losses\n",
      "transactions with stocks from the czech energy enterprise cez reached nearly half of the regular daily trading\n",
      "the prague stock market immediately continued its fall from monday at the beginning of tuesdays trading when it dropped by nearly six percent\n",
      "this time the fall in stocks on wall street is responsible for the drop\n",
      "the reaction of the market to the results of the vote in the american house of representatives which refused to support the plan for the stabilization of the financial sector there has manifested itself here as well\n",
      "stocks fall in asia\n",
      "stocks in the asian markets experienced a dramatic drop on tuesday even though the indexes ultimately erased a part of the losses during the day\n",
      "the hang seng index of the hong kong stock exchange wrote off nearly four percent during the day but later it erased a part of the losses and reduced the decrease to roughly percent\n",
      "the hang seng china enterprises index which follows the movement of chinese stocks on the stock market in hong kong dropped by percent in shanghai the markets were closed\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2009.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'english2009.pkl')\n",
    "\n",
    "#spot check for english version\n",
    "for i in range(5):\n",
    "\tprint(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary: 8601\n"
     ]
    }
   ],
   "source": [
    "# load English dataset i.e pickled earlier\n",
    "filename = 'english2009.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "\n",
    "# calculate vocabulary\n",
    "vocab = to_vocab(lines)\n",
    "print('English Vocabulary: %d' % len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_2009= pd.read_pickle('english2009.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_clean_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009=pd.DataFrame(ls_2009, columns=['eng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prague stock market falls to minus by the end of the trading day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>after a sharp drop in the morning the prague stock market corrected its losses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              eng\n",
       "0                prague stock market falls to minus by the end of the trading day\n",
       "1  after a sharp drop in the morning the prague stock market corrected its losses"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2009.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2525, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2009.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english2010.pkl\n",
      "barack obama becomes the fourth american president to receive the nobel peace prize\n",
      "the american president barack obama will fly into oslo norway for hours to receive the nobel peace prize the fourth american president in history to do so\n",
      "he will receive a diploma medal and cheque for million dollars for his exceptional efforts to improve global diplomacy and encourage international cooperation amongst other things\n",
      "the head of the white house will be flying into the norwegian city in the morning with his wife michelle and will have a busy schedule\n",
      "first he will visit the nobel institute where he will have his first meeting with the five committee members who selected him from people and organisations\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2010.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'english2010.pkl')\n",
    "\n",
    "#spot check for english version\n",
    "for i in range(5):\n",
    "\tprint(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary: 8526\n"
     ]
    }
   ],
   "source": [
    "# load English dataset i.e pickled earlier\n",
    "filename = 'english2010.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "\n",
    "# calculate vocabulary\n",
    "vocab = to_vocab(lines)\n",
    "print('English Vocabulary: %d' % len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_2010= pd.read_pickle('english2010.pkl')\n",
    "type(ls_2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2489, 1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2010=pd.DataFrame(ls_2010, columns=['eng'])\n",
    "df_2010.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barack obama becomes the fourth american president to receive the nobel peace prize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the american president barack obama will fly into oslo norway for hours to receive the nobel peace prize the fourth american president in history to do so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he will receive a diploma medal and cheque for million dollars for his exceptional efforts to improve global diplomacy and encourage international cooperation amongst other things</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                   eng\n",
       "0                                                                                                  barack obama becomes the fourth american president to receive the nobel peace prize\n",
       "1                           the american president barack obama will fly into oslo norway for hours to receive the nobel peace prize the fourth american president in history to do so\n",
       "2  he will receive a diploma medal and cheque for million dollars for his exceptional efforts to improve global diplomacy and encourage international cooperation amongst other things"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2010.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english2011.pkl\n",
      "what will they do cssd lacks knowledge of both voldemort and candy bars in prague\n",
      "new councilors of cssd will most probably have to overcome certain language barriers to understand their oldnew colleagues from ods in prague council and municipal council\n",
      "aktualnecz tested the social democrat members of the new council in terms of the wellestablished slang that originated in the town hall during the few last years when prague was ruled by the current coalition partners\n",
      "coded vocabulary that was established by prague political elite during the previous era of the mayor pavel bem describes some of the most famous persons situations and affairs in the city\n",
      "surprisingly it turned out that the new council members do not understand the wellknown concepts\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2011.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'english2011.pkl')\n",
    "\n",
    "#spot check for english version\n",
    "for i in range(5):\n",
    "\tprint(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary: 9868\n"
     ]
    }
   ],
   "source": [
    "# load English dataset i.e pickled earlier\n",
    "filename = 'english2011.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "\n",
    "# calculate vocabulary\n",
    "vocab = to_vocab(lines)\n",
    "print('English Vocabulary: %d' % len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_2011= pd.read_pickle('english2011.pkl')\n",
    "type(ls_2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3003, 1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2011=pd.DataFrame(ls_2011, columns=['eng'])\n",
    "df_2011.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what will they do cssd lacks knowledge of both voldemort and candy bars in prague</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new councilors of cssd will most probably have to overcome certain language barriers to understand their oldnew colleagues from ods in prague council and municipal council</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aktualnecz tested the social democrat members of the new council in terms of the wellestablished slang that originated in the town hall during the few last years when prague was ruled by the curre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                       eng\n",
       "0                                                                                                                        what will they do cssd lacks knowledge of both voldemort and candy bars in prague\n",
       "1                              new councilors of cssd will most probably have to overcome certain language barriers to understand their oldnew colleagues from ods in prague council and municipal council\n",
       "2  aktualnecz tested the social democrat members of the new council in terms of the wellestablished slang that originated in the town hall during the few last years when prague was ruled by the curre..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2011.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english2012.pkl\n",
      "parliament does not support amendment freeing tymoshenko\n",
      "today the ukraine parliament dismissed within the code of criminal procedure amendment the motion to revoke an article based on which the opposition leader yulia tymoshenko was sentenced\n",
      "the amendment that would lead to freeing the imprisoned former prime minister was revoked during second reading of the proposal for mitigation of sentences for economic offences\n",
      "in october tymoshenko was sentenced to seven years in prison for entering into what was reported to be a disadvantageous gas deal with russia\n",
      "the verdict is not yet final the court will hear tymoshenkos appeal in december\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2012.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'english2012.pkl')\n",
    "\n",
    "#spot check for english version\n",
    "for i in range(5):\n",
    "\tprint(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary: 9138\n"
     ]
    }
   ],
   "source": [
    "# load English dataset i.e pickled earlier\n",
    "filename = 'english2012.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "\n",
    "# calculate vocabulary\n",
    "vocab = to_vocab(lines)\n",
    "print('English Vocabulary: %d' % len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_2012= pd.read_pickle('english2012.pkl')\n",
    "type(ls_2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3003, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2012=pd.DataFrame(ls_2012, columns=['eng'])\n",
    "df_2012.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>parliament does not support amendment freeing tymoshenko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>today the ukraine parliament dismissed within the code of criminal procedure amendment the motion to revoke an article based on which the opposition leader yulia tymoshenko was sentenced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the amendment that would lead to freeing the imprisoned former prime minister was revoked during second reading of the proposal for mitigation of sentences for economic offences</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                          eng\n",
       "0                                                                                                                                    parliament does not support amendment freeing tymoshenko\n",
       "1  today the ukraine parliament dismissed within the code of criminal procedure amendment the motion to revoke an article based on which the opposition leader yulia tymoshenko was sentenced\n",
       "2           the amendment that would lead to freeing the imprisoned former prime minister was revoked during second reading of the proposal for mitigation of sentences for economic offences"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2012.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english2013.pkl\n",
      "a republican strategy to counter the reelection of obama\n",
      "republican leaders justified their policy by the need to combat electoral fraud\n",
      "however the brennan centre considers this a myth stating that electoral fraud is rarer in the united states than the number of people killed by lightning\n",
      "indeed republican lawyers identified only cases of electoral fraud in the united states in a decade\n",
      "one thing is certain these new provisions will have a negative impact on voter turnout\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2013.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'english2013.pkl')\n",
    "\n",
    "#spot check for english version\n",
    "for i in range(5):\n",
    "\tprint(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary: 8629\n"
     ]
    }
   ],
   "source": [
    "# load English dataset i.e pickled earlier\n",
    "filename = 'english2013.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "\n",
    "# calculate vocabulary\n",
    "vocab = to_vocab(lines)\n",
    "print('English Vocabulary: %d' % len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_2013= pd.read_pickle('english2013.pkl')\n",
    "type(ls_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2013=pd.DataFrame(ls_2013, columns=['eng'])\n",
    "df_2013.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a republican strategy to counter the reelection of obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>republican leaders justified their policy by the need to combat electoral fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>however the brennan centre considers this a myth stating that electoral fraud is rarer in the united states than the number of people killed by lightning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                         eng\n",
       "0                                                                                                   a republican strategy to counter the reelection of obama\n",
       "1                                                                            republican leaders justified their policy by the need to combat electoral fraud\n",
       "2  however the brennan centre considers this a myth stating that electoral fraud is rarer in the united states than the number of people killed by lightning"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2013.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english2014.pkl\n",
      "gutach increased safety for pedestrians\n",
      "they are not even metres apart on tuesday the new b pedestrian lights in dorfparkplatz in gutach became operational within view of the existing town hall traffic lights\n",
      "two sets of lights so close to one another intentional or just a silly error\n",
      "yesterday gutachts mayor gave a clear answer to this question\n",
      "at the time the town hall traffic lights were installed because this was a school route explained eckert yesterday\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2014.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'english2014.pkl')\n",
    "\n",
    "#spot check for english version\n",
    "for i in range(5):\n",
    "\tprint(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary: 9290\n"
     ]
    }
   ],
   "source": [
    "# load English dataset i.e pickled earlier\n",
    "filename = 'english2014.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "\n",
    "# calculate vocabulary\n",
    "vocab = to_vocab(lines)\n",
    "print('English Vocabulary: %d' % len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_2014= pd.read_pickle('english2014.pkl')\n",
    "type(ls_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3003, 1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2014=pd.DataFrame(ls_2014, columns=['eng'])\n",
    "df_2014.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gutach increased safety for pedestrians</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>they are not even metres apart on tuesday the new b pedestrian lights in dorfparkplatz in gutach became operational within view of the existing town hall traffic lights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>two sets of lights so close to one another intentional or just a silly error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                        eng\n",
       "0                                                                                                                                   gutach increased safety for pedestrians\n",
       "1  they are not even metres apart on tuesday the new b pedestrian lights in dorfparkplatz in gutach became operational within view of the existing town hall traffic lights\n",
       "2                                                                                              two sets of lights so close to one another intentional or just a silly error"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2014.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english2015.pkl\n",
      "india and japan prime ministers meet in tokyo\n",
      "indias new prime minister narendra modi is meeting his japanese counterpart shinzo abe in tokyo to discuss economic and security ties on his first major foreign visit since winning mays election\n",
      "mr modi is on a fiveday trip to japan to strengthen economic ties with the third largest economy in the world\n",
      "high on the agenda are plans for greater nuclear cooperation\n",
      "india is also reportedly hoping for a deal on defence collaboration between the two nations\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2015.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'english2015.pkl')\n",
    "\n",
    "#spot check for english version\n",
    "for i in range(5):\n",
    "\tprint(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary: 7227\n"
     ]
    }
   ],
   "source": [
    "# load English dataset i.e pickled earlier\n",
    "filename = 'english2015.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "\n",
    "# calculate vocabulary\n",
    "vocab = to_vocab(lines)\n",
    "print('English Vocabulary: %d' % len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_2015= pd.read_pickle('english2015.pkl')\n",
    "type(ls_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2169, 1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2015=pd.DataFrame(ls_2015, columns=['eng'])\n",
    "df_2015.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>india and japan prime ministers meet in tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indias new prime minister narendra modi is meeting his japanese counterpart shinzo abe in tokyo to discuss economic and security ties on his first major foreign visit since winning mays election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mr modi is on a fiveday trip to japan to strengthen economic ties with the third largest economy in the world</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                  eng\n",
       "0                                                                                                                                                       india and japan prime ministers meet in tokyo\n",
       "1  indias new prime minister narendra modi is meeting his japanese counterpart shinzo abe in tokyo to discuss economic and security ties on his first major foreign visit since winning mays election\n",
       "2                                                                                       mr modi is on a fiveday trip to japan to strengthen economic ties with the third largest economy in the world"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2015.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english2016.pkl\n",
      "obama receives netanyahu\n",
      "the relationship between obama and netanyahu is not exactly friendly\n",
      "the two wanted to talk about the implementation of the international agreement and about teherans destabilising activities in the middle east\n",
      "the meeting was also planned to cover the conflict with the palestinians and the disputed two state solution\n",
      "relations between obama and netanyahu have been strained for years\n"
     ]
    }
   ],
   "source": [
    "# load English data\n",
    "filename = 'newstest2016.en'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'english2016.pkl')\n",
    "\n",
    "#spot check for english version\n",
    "for i in range(5):\n",
    "\tprint(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary: 8696\n"
     ]
    }
   ],
   "source": [
    "# load English dataset i.e pickled earlier\n",
    "filename = 'english2016.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "\n",
    "# calculate vocabulary\n",
    "vocab = to_vocab(lines)\n",
    "print('English Vocabulary: %d' % len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_2016= pd.read_pickle('english2016.pkl')\n",
    "type(ls_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 1)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016=pd.DataFrame(ls_2016, columns=['eng'])\n",
    "df_2016.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>obama receives netanyahu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the relationship between obama and netanyahu is not exactly friendly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the two wanted to talk about the implementation of the international agreement and about teherans destabilising activities in the middle east</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             eng\n",
       "0                                                                                                                       obama receives netanyahu\n",
       "1                                                                           the relationship between obama and netanyahu is not exactly friendly\n",
       "2  the two wanted to talk about the implementation of the international agreement and about teherans destabilising activities in the middle east"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**combine all datasets from 2009-2016**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_all=pd.concat([df_2009,df_2010,df_2011,df_2012,df_2013,df_2014,df_2015,df_2016], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of combined Cleaned English version is (22191, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of combined Cleaned English version is\", df_eng_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save as text file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_all.to_csv(r'english_all.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b.all german version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and check German data\n",
    "\n",
    "filename = 'newstest2015.de'\n",
    "doc = load_doc(filename)\n",
    "sentences = to_sentences(doc)\n",
    "sentences = clean_lines(sentences)\n",
    "save_clean_sentences(sentences, 'german2015.pkl')\n",
    "# spot check for german version\n",
    "for i in range(10):\n",
    "\tprint(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load German dataset i.e pickled earlier\n",
    "filename = 'german2015.pkl'\n",
    "lines = load_clean_sentences(filename)\n",
    "# calculate vocabulary\n",
    "vocab = to_vocab(lines)\n",
    "print('German Vocabulary: %d' % len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6c. Make them random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**again make test_text file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Preprocess.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
